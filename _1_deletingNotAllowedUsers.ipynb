{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "584eeac6",
   "metadata": {},
   "source": [
    "# Data Cleaning and Preprocessing "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40baa1d8",
   "metadata": {},
   "source": [
    "#### adding required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "056016ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\zahraeftekhar\\.conda\\envs\\r-tutorial\\lib\\site-packages (1.3.2)\n",
      "Requirement already satisfied: numpy>=1.17.3 in c:\\users\\zahraeftekhar\\.conda\\envs\\r-tutorial\\lib\\site-packages (from pandas) (1.21.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in c:\\users\\zahraeftekhar\\.conda\\envs\\r-tutorial\\lib\\site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2017.3 in c:\\users\\zahraeftekhar\\.conda\\envs\\r-tutorial\\lib\\site-packages (from pandas) (2021.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\zahraeftekhar\\.conda\\envs\\r-tutorial\\lib\\site-packages (from python-dateutil>=2.7.3->pandas) (1.16.0)\n",
      "Collecting xmltodict\n",
      "  Downloading xmltodict-0.12.0-py2.py3-none-any.whl (9.2 kB)\n",
      "Installing collected packages: xmltodict\n",
      "Successfully installed xmltodict-0.12.0\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas\n",
    "!pip install xmltodict\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xmltodict\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bee4ab08",
   "metadata": {},
   "source": [
    "#### specifying the saving location "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "fe20091f",
   "metadata": {},
   "outputs": [],
   "source": [
    "savingLoc = \"Y:/ZahraEftekhar/phase4/\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a96a110",
   "metadata": {},
   "source": [
    "## 1) keeping allowed users from the MATSim files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4879c396",
   "metadata": {},
   "source": [
    "In this step we use the `1.experienced_plans.xml` and `snapShot.CSV` file in the MATsim output folder. We would like to only keep the users with the `car` mode. Furthermore, we remove users with zero duration activities. The users we keep are the same in both of the mentioned files. Finally, after this data cleaning we end up with about 21,000 users. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bda07841",
   "metadata": {},
   "source": [
    "#### reading `1.experienced_plans.xml` and converting it to a dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bf764bf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "263.1187858581543 seconds\n"
     ]
    }
   ],
   "source": [
    "#we time the process\n",
    "startTime = time.time()\n",
    "\n",
    "# reading the MATSim output into a dict file\n",
    "tree = xmltodict.parse(open(\"{a}1.experienced_plans.xml\".format(a=savingLoc),\"rb\"))\n",
    "# tree = xmltodict.parse(open(\"/data/zahraeftekhar/research_temporal/input_base/1.experienced_plans.xml\",\"rb\"))\n",
    "\n",
    "# root is a list of plans of the users \n",
    "root = tree['population']['person'] \n",
    "del tree\n",
    "print(time.time() - startTime,'seconds')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8c0e750",
   "metadata": {},
   "source": [
    "#### keeping only users with the `car` mode and removing users with unacceptable travel diary:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c6e5430",
   "metadata": {},
   "source": [
    "Here, we want to extract the user IDs that need to be removed them from our data set. This includes the users with non-positive activity durations, users with less than three activities which show no travel, etc. Also we only consider users with the mode `car`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6d18bd57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.3839805126190186 seconds\n"
     ]
    }
   ],
   "source": [
    "#we time the process\n",
    "startTime = time.time()\n",
    "\n",
    "RemoveIDs = []\n",
    "for child in root:\n",
    "    try:\n",
    "        # remove IDs that did not travel\n",
    "        if len(child[\"plan\"][\"activity\"])<3:\n",
    "            RemoveIDs += [child['@id']]\n",
    "\n",
    "        # remove IDs that used any mode other than `car`\n",
    "        elif not all(flag[\"@mode\"] == \"car\" for flag in child['plan']['leg']):\n",
    "            RemoveIDs += [child['@id']]\n",
    "\n",
    "        # remove IDs that their 1st and last activity are not similar\n",
    "        # this is done to be able to have a round travel diary\n",
    "        elif child[\"plan\"][\"activity\"][0][\"@type\"]!=child[\"plan\"][\"activity\"][-1][\"@type\"]:\n",
    "            RemoveIDs += [child['@id']]\n",
    "\n",
    "        # remove IDs with zero duration activities:\n",
    "        # 1) removing `generic`legs because they usually lead to zero duration activities\n",
    "        elif not all(flag['route']['@type'] != 'generic' for flag in child['plan']['leg']):\n",
    "            RemoveIDs += [child['@id']]\n",
    "\n",
    "        # 2) remove the rest of IDs with zero or negative duration activities\n",
    "        elif not all((pd.to_timedelta(flag['@end_time'])).total_seconds() -\n",
    "                     (pd.to_timedelta(flag['@start_time'])).total_seconds() > 0\n",
    "                     for flag in child['plan']['activity'][1:-1]):\n",
    "            RemoveIDs += [child['@id']]\n",
    "    except KeyError:\n",
    "        RemoveIDs += [child['@id']]\n",
    "print(time.time() - startTime,'seconds')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d40860c4",
   "metadata": {},
   "source": [
    "### 1.1) removing `RemoveIDs` from travel diaries (`1.experienced_plans.xml`)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a64ff377",
   "metadata": {},
   "source": [
    "Here, we remove the IDs inside `RemoveIDs` from the travel diaries dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "7679fce5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22208\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>plan</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>{'@score': '103.65231197449688', '@selected': ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>{'@score': '101.84174881258225', '@selected': ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100007</td>\n",
       "      <td>{'@score': '105.56505677006494', '@selected': ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100009</td>\n",
       "      <td>{'@score': '104.99507686427171', '@selected': ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10001</td>\n",
       "      <td>{'@score': '105.92977435468114', '@selected': ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     plan\n",
       "id                                                       \n",
       "1       {'@score': '103.65231197449688', '@selected': ...\n",
       "10      {'@score': '101.84174881258225', '@selected': ...\n",
       "100007  {'@score': '105.56505677006494', '@selected': ...\n",
       "100009  {'@score': '104.99507686427171', '@selected': ...\n",
       "10001   {'@score': '105.92977435468114', '@selected': ..."
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# number of users after data cleaning\n",
    "print(len(root)-len(RemoveIDs))\n",
    "\n",
    "cleanedData = pd.DataFrame.from_dict(root)\n",
    "del root\n",
    "cleanedData.columns = ['id', 'plan']\n",
    "cleanedData.set_index('id',inplace=True) \n",
    "cleanedData.drop(RemoveIDs, inplace=True)\n",
    "cleanedData.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad1cb27d",
   "metadata": {},
   "source": [
    "Now, we have to fix the error in the location coordinates of the travel diaries (for some unknown reasons). The location problem only exist in the travel diaries NOT the snapShot file (representing the GSM data). At the end we generate a `dict` of final round travel diaries with `key` of each vehicle ID and their associated panda DataFrame with columns: `VEHICLE`,`activityType`,`x`,`y`,`start`,`end`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "5da605ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "links = (xmltodict.parse(open(\"{a}output_network.xml\".format(a=savingLoc),\"rb\")))[\"network\"][\"links\"][\"link\"]\n",
    "nodes = (xmltodict.parse(open(\"{a}output_network.xml\".format(a=savingLoc),\"rb\")))[\"network\"][\"nodes\"][\"node\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "1d3348fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24.0 minutess\n"
     ]
    }
   ],
   "source": [
    "#we time the process\n",
    "startTime = time.time()\n",
    "\n",
    "trueLocations = {}\n",
    "for ID in cleanedData.index:\n",
    "    legList = [(flag['route']) for flag in cleanedData.loc[ID,:]['plan']['leg']]\n",
    "    activityList = cleanedData.loc[ID,:]['plan']['activity']\n",
    "    person = pd.DataFrame(columns=['VEHICLE','activityType','x','y','start','end'])\n",
    "    i=0\n",
    "    for i in range(len(legList)):\n",
    "        trueloc = pd.DataFrame(columns=['VEHICLE','activityType','x','y','start','end'])\n",
    "        trueloc.loc[0,'VEHICLE'] = ID\n",
    "        trueloc.loc[0,'activityType'] = activityList[i+1]['@type']\n",
    "       \n",
    "        trueloc.loc[0,'start'] = activityList[i+1]['@start_time']\n",
    "        try:\n",
    "            trueloc.loc[0,'end'] = activityList[i+1]['@end_time']\n",
    "        except KeyError:\n",
    "            trueloc.loc[0,'end'] = activityList[0]['@end_time']\n",
    "        linkID = legList[i]['@end_link']\n",
    "        for j in range(len(links)):\n",
    "            if links[j][\"@id\"]==linkID:\n",
    "                nod = links[j][\"@to\"]\n",
    "                for k in range(len(nodes)):\n",
    "                    if nodes[k]['@id']==nod:\n",
    "                        trueloc.loc[0,'x'] = nodes[k]['@x']\n",
    "                        trueloc.loc[0,'y'] = nodes[k]['@y']\n",
    "        person = person.append(trueloc)\n",
    "    trueLocations[ID] = person\n",
    "import pickle\n",
    "with open('{a}1.trueLocExperienced.pickle'.format(a=savingLoc),'wb') as handle:\n",
    "    pickle.dump(trueLocations, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "print((time.time() - startTime)//60,'minutess')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "b6eda84c",
   "metadata": {},
   "outputs": [],
   "source": [
    "del trueLocations, cleanedData"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34ad9677",
   "metadata": {},
   "source": [
    "### 1.2) removing `RemoveIDs` from GSm data (`snapShot.CSV`)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5429ac4",
   "metadata": {},
   "source": [
    "So far we cleaned the `1.experienced_plans.xml` file with the right users, location coordinates and  and travel diaries. Finally, we saved it as a `dict` file named `1.trueLocExperienced.pickle`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "id": "eec2b2d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35.0 minutess\n"
     ]
    }
   ],
   "source": [
    "#we time the process\n",
    "startTime = time.time()\n",
    "\n",
    "snapFile = pd.read_csv(\"{a}snapShot.CSV\".format(a=savingLoc),delimiter=\"\\t\", \n",
    "                       usecols = ['VEHICLE', 'TIME','EASTING', 'NORTHING'],\n",
    "                       index_col = \"VEHICLE\").sort_index(level=\"VEHICLE\")\n",
    "allowedIDs = [i for i in snapFile.index.unique() if i not in np.array(RemoveIDs, dtype=np.int)]\n",
    "gsmFile = snapFile.loc[allowedIDs,:]\n",
    "import pickle\n",
    "with open('{a}snapShot_allowedUsers.pickle'.format(a=savingLoc),'wb') as handle:\n",
    "    pickle.dump(gsmFile, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    \n",
    "print((time.time() - startTime)//60,'minutess')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6feaff9b",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pandas'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-d76d6ccfe757>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0msavingLoc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"Y:/ZahraEftekhar/phase4/\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'{a}1.trueLocExperienced.pickle'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msavingLoc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'rb'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[0mkk\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'{a}snapShot_allowedUsers.pickle'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msavingLoc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'rb'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0mgsmFile\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'pandas'"
     ]
    }
   ],
   "source": [
    "savingLoc = \"Y:/ZahraEftekhar/phase4/\"\n",
    "with open('{a}1.trueLocExperienced.pickle'.format(a=savingLoc), 'rb') as handle:\n",
    "    kk = pickle.load(handle)\n",
    "with open('{a}snapShot_allowedUsers.pickle'.format(a=savingLoc), 'rb') as handle:\n",
    "    gsmFile = pickle.load(handle)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "id": "d18992b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22208"
      ]
     },
     "execution_count": 314,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# number of users in the travel diaries:\n",
    "len(kk.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "338e5577",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'gsmFile' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-c562abfe0a0c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# number of users in the GSM data:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgsmFile\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'gsmFile' is not defined"
     ]
    }
   ],
   "source": [
    "# number of users in the GSM data:\n",
    "len(gsmFile.index.unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6ea47bd",
   "metadata": {},
   "source": [
    "the number of users in travel diaries and GSM data (`snapShot` file) is almost the same and the 2 user difference does not cause any significant problem. Therefore, we save and move on with these users in both cleaned files."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
