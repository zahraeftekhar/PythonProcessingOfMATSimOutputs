{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SnapShot preprocessing:\n",
    "In this notebook we get the MATSim snapShot output as the input. MATSim gives us the user location in constant intervals. It does not report anything when the user is not traveling. So to make this data as much as possible closer to the actual periodic location update, we have to fill in the empty records. also we initially get the snapshots every 30 seconds. For other polling intervals we only reduce the accuracy. Also for the spatial aggregation to the level os TAZ zones, we use arcGIS to extract the associated TAZ of each location record from the snapShot file. The output of arcGIS is the input here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### adding required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import time\n",
    "from math import floor\n",
    "import numpy as np\n",
    "import pickle\n",
    "import requests\n",
    "import concurrent.futures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### specifying the saving location "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "savingLoc = \"Y:/ZahraEftekhar/phase4/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### preparing the output of arcGIS for completion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output of GIS misses the locations outside of Amsterdam. Therefore, we complete the data by considering their TAZ code `0`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7481  records are missing that we refill them in our snapShot. \n"
     ]
    }
   ],
   "source": [
    "precompletion = pd.read_csv('{a}GISoutput_PreCompletion.CSV'.format(a=savingLoc),usecols=['mzr_id', 'VEHICLE','TIME','EASTING','NORTHING'])\n",
    "precompletion = precompletion.sort_values(by=[\"VEHICLE\",\"TIME\"])\n",
    "precompletion = precompletion.reset_index(drop=True)\n",
    "with open('{a}snapShot_allowedUsers.pickle'.format(a=savingLoc),'rb') as handle:\n",
    "    MATSimOutput = pickle.load(handle)\n",
    "MATSimOutput=MATSimOutput.reset_index(drop=False)\n",
    "print(len(MATSimOutput)-len(precompletion),\" records are missing that we refill them in our snapShot. \")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\programdata\\anaconda3\\envs\\extractingodfromxml\\lib\\site-packages\\ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "snapData = pd.merge(precompletion, MATSimOutput, how='right', on=['VEHICLE','TIME'])\n",
    "(snapData.mzr_id[snapData.mzr_id.isna()]) = 0\n",
    "snapData = snapData.loc[:,['VEHICLE','TIME','EASTING_y','NORTHING_y','mzr_id']]\n",
    "snapData.columns = ['VEHICLE', 'TIME', 'EASTING', 'NORTHING', 'mzr_id']\n",
    "snapData = snapData.sort_values(by = ['VEHICLE', 'TIME'])\n",
    "with open('{a}finalInputPython.pickle'.format(a=savingLoc),'wb') as handle:\n",
    "    pickle.dump(snapData, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, it is time to generate the complete snapShot data for every 30 seconds which represents the base data set even for generating other snapshots with different polling intervals (we resample from this data based on the specified polling interval)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>VEHICLE</th>\n",
       "      <th>TIME</th>\n",
       "      <th>EASTING</th>\n",
       "      <th>NORTHING</th>\n",
       "      <th>mzr_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>23400</td>\n",
       "      <td>632364.770972</td>\n",
       "      <td>5.816900e+06</td>\n",
       "      <td>7065.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>23430</td>\n",
       "      <td>632279.680941</td>\n",
       "      <td>5.816846e+06</td>\n",
       "      <td>5329.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>23460</td>\n",
       "      <td>632234.315601</td>\n",
       "      <td>5.816431e+06</td>\n",
       "      <td>5329.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>23490</td>\n",
       "      <td>632200.291596</td>\n",
       "      <td>5.816119e+06</td>\n",
       "      <td>5329.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>23520</td>\n",
       "      <td>632209.756236</td>\n",
       "      <td>5.815776e+06</td>\n",
       "      <td>5329.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   VEHICLE   TIME        EASTING      NORTHING  mzr_id\n",
       "0        1  23400  632364.770972  5.816900e+06  7065.0\n",
       "1        1  23430  632279.680941  5.816846e+06  5329.0\n",
       "2        1  23460  632234.315601  5.816431e+06  5329.0\n",
       "3        1  23490  632200.291596  5.816119e+06  5329.0\n",
       "4        1  23520  632209.756236  5.815776e+06  5329.0"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('{a}finalInputPython.pickle'.format(a=savingLoc),'rb') as handle:\n",
    "    snapData = pickle.load(handle)\n",
    "snapData.reset_index(drop=True,inplace=True)\n",
    "snapData.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1:                  VEHICLE        EASTING      NORTHING  mzr_id\n",
      "TIME                                                         \n",
      "0 days 06:30:00      1.0  632364.770972  5.816900e+06  7065.0\n",
      "0 days 06:30:30      1.0  632279.680941  5.816846e+06  5329.0\n",
      "0 days 06:31:00      1.0  632234.315601  5.816431e+06  5329.0\n",
      "0 days 06:31:30      1.0  632200.291596  5.816119e+06  5329.0\n",
      "0 days 06:32:00      1.0  632209.756236  5.815776e+06  5329.0\n",
      "...                  ...            ...           ...     ...\n",
      "1 days 06:27:30      1.0  632318.660822  5.816858e+06  5329.0\n",
      "1 days 06:28:00      1.0  632318.660822  5.816858e+06  5329.0\n",
      "1 days 06:28:30      1.0  632318.660822  5.816858e+06  5329.0\n",
      "1 days 06:29:00      1.0  632318.660822  5.816858e+06  5329.0\n",
      "1 days 06:29:30      1.0  632318.660822  5.816858e+06  5329.0\n",
      "\n",
      "[2880 rows x 4 columns], 30:                  VEHICLE        EASTING      NORTHING  mzr_id\n",
      "TIME                                                         \n",
      "0 days 06:19:30     30.0  640266.661604  5.811505e+06  5931.0\n",
      "0 days 06:20:00     30.0  640259.204096  5.811514e+06  5931.0\n",
      "0 days 06:20:30     30.0  640249.260753  5.811525e+06  5931.0\n",
      "0 days 06:21:00     30.0  640241.803245  5.811533e+06  5931.0\n",
      "0 days 06:21:30     30.0  640229.374066  5.811547e+06  5931.0\n",
      "...                  ...            ...           ...     ...\n",
      "1 days 06:17:00     30.0  640214.307303  5.811589e+06  5931.0\n",
      "1 days 06:17:30     30.0  640214.307303  5.811589e+06  5931.0\n",
      "1 days 06:18:00     30.0  640214.307303  5.811589e+06  5931.0\n",
      "1 days 06:18:30     30.0  640214.307303  5.811589e+06  5931.0\n",
      "1 days 06:19:00     30.0  640214.307303  5.811589e+06  5931.0\n",
      "\n",
      "[2880 rows x 4 columns]}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\programdata\\anaconda3\\envs\\extractingodfromxml\\lib\\site-packages\\pandas\\core\\generic.py:5516: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self[name] = value\n",
      "c:\\programdata\\anaconda3\\envs\\extractingodfromxml\\lib\\site-packages\\pandas\\core\\indexing.py:723: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  iloc._setitem_with_indexer(indexer, value, self.name)\n"
     ]
    }
   ],
   "source": [
    "userGroups = (snapData.groupby([\"VEHICLE\"]))\n",
    "kkk = {}\n",
    "# for ID in \n",
    "kk = userGroups.get_group(1)\n",
    "kk.TIME = pd.to_timedelta(kk.TIME, unit=\"s\")\n",
    "kk.set_index([\"TIME\"],inplace=True)\n",
    "# print(kk.tail())\n",
    "kk.loc[kk.index[0]+pd.to_timedelta('24:00:00')]=kk.iloc[0,:]\n",
    "kk.sort_index(inplace=True)\n",
    "kk = kk.resample('30S').fillna(\"pad\")\n",
    "kk.drop([kk.index[0]+pd.to_timedelta('24:00:00')],axis=0,inplace=True)\n",
    "# kk.reset_index(drop=False, inplace=True)\n",
    "kkk[1] = kk\n",
    "kk = userGroups.get_group(30)\n",
    "kk.TIME = pd.to_timedelta(kk.TIME, unit=\"s\")\n",
    "kk.set_index([\"TIME\"],inplace=True)\n",
    "# print(kk.tail())\n",
    "kk.loc[kk.index[0]+pd.to_timedelta('24:00:00')]=kk.iloc[0,:]\n",
    "kk.sort_index(inplace=True)\n",
    "kk = kk.resample('30S').fillna(\"pad\")\n",
    "kk.drop([kk.index[0]+pd.to_timedelta('24:00:00')],axis=0,inplace=True)\n",
    "# kk.reset_index(drop=False, inplace=True)\n",
    "kkk[30] = kk\n",
    "# kkk = pd.DataFrame(kkk)\n",
    "print(kkk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\programdata\\anaconda3\\envs\\extractingodfromxml\\lib\\site-packages\\pandas\\core\\generic.py:5516: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self[name] = value\n",
      "c:\\programdata\\anaconda3\\envs\\extractingodfromxml\\lib\\site-packages\\pandas\\core\\indexing.py:723: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  iloc._setitem_with_indexer(indexer, value, self.name)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-110-8cb270b5751c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[0msnapDataNew\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mID\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mconcatData\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m     \u001b[0msnapDataNew\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msnapDataNew\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconcatData\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mID\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     22\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"completePLUdata_30sec.pickle\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msavingLoc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"wb\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m           \u001b[0mpickle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msnapDataNew\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprotocol\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpickle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mHIGHEST_PROTOCOL\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\programdata\\anaconda3\\envs\\extractingodfromxml\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36mappend\u001b[1;34m(self, other, ignore_index, verify_integrity, sort)\u001b[0m\n\u001b[0;32m   8963\u001b[0m                 \u001b[0mignore_index\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mignore_index\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   8964\u001b[0m                 \u001b[0mverify_integrity\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mverify_integrity\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 8965\u001b[1;33m                 \u001b[0msort\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msort\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   8966\u001b[0m             )\n\u001b[0;32m   8967\u001b[0m         ).__finalize__(self, method=\"append\")\n",
      "\u001b[1;32mc:\\programdata\\anaconda3\\envs\\extractingodfromxml\\lib\\site-packages\\pandas\\util\\_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    310\u001b[0m                 )\n\u001b[1;32m--> 311\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    312\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    313\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\programdata\\anaconda3\\envs\\extractingodfromxml\\lib\\site-packages\\pandas\\core\\reshape\\concat.py\u001b[0m in \u001b[0;36mconcat\u001b[1;34m(objs, axis, join, ignore_index, keys, levels, names, verify_integrity, sort, copy)\u001b[0m\n\u001b[0;32m    305\u001b[0m     )\n\u001b[0;32m    306\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 307\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    308\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    309\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\programdata\\anaconda3\\envs\\extractingodfromxml\\lib\\site-packages\\pandas\\core\\reshape\\concat.py\u001b[0m in \u001b[0;36mget_result\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    531\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    532\u001b[0m             new_data = concatenate_managers(\n\u001b[1;32m--> 533\u001b[1;33m                 \u001b[0mmgrs_indexers\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnew_axes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconcat_axis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbm_axis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    534\u001b[0m             )\n\u001b[0;32m    535\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\programdata\\anaconda3\\envs\\extractingodfromxml\\lib\\site-packages\\pandas\\core\\internals\\concat.py\u001b[0m in \u001b[0;36mconcatenate_managers\u001b[1;34m(mgrs_indexers, axes, concat_axis, copy)\u001b[0m\n\u001b[0;32m    214\u001b[0m                 \u001b[1;31m#  we can use np.concatenate, which is more performant\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    215\u001b[0m                 \u001b[1;31m#  than concat_compat\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 216\u001b[1;33m                 \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvals\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mblk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m-\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    217\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    218\u001b[0m                 \u001b[1;31m# TODO(EA2D): special-casing not needed with 2D EAs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mconcatenate\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#we time the process\n",
    "startTime = time.time()\n",
    "\n",
    "userGroups = (snapData.groupby([\"VEHICLE\"]))\n",
    "concatData = {}\n",
    "for ID in userGroups.groups.keys():\n",
    "    records=userGroups.get_group(ID)\n",
    "    records.TIME = pd.to_timedelta(records.TIME, unit=\"s\")\n",
    "    records.set_index([\"TIME\"],inplace=True)\n",
    "    # print(kk.tail())\n",
    "    records.loc[records.index[0]+pd.to_timedelta('24:00:00')]=records.iloc[0,:]\n",
    "    records.sort_index(inplace=True)\n",
    "    records = records.resample('30S').fillna(\"pad\")\n",
    "    records.drop([records.index[0]+pd.to_timedelta('24:00:00')],axis=0,inplace=True)\n",
    "    # kk.reset_index(drop=False, inplace=True)\n",
    "    concatData[ID] = kk\n",
    "with open(\"completePLUdata_30sec_dict.pickle\".format(a=savingLoc),\"wb\") as handle:\n",
    "          pickle.dump(concatData,handle, protocol=pickle.HIGHEST_PROTOCOL )\n",
    "snapDataNew = pd.DataFrame()\n",
    "for ID in concatData.keys():\n",
    "    snapDataNew = snapDataNew.append(concatData[ID])\n",
    "with open(\"completePLUdata_30sec.pickle\".format(a=savingLoc),\"wb\") as handle:\n",
    "          pickle.dump(snapDataNew,handle, protocol=pickle.HIGHEST_PROTOCOL )\n",
    "print((time.time() - startTime)//60,'minutes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0 minutes\n"
     ]
    }
   ],
   "source": [
    "#we time the process\n",
    "startTime = time.time()\n",
    "concatData = pd.DataFrame()\n",
    "userGroups = (snapData.groupby([\"VEHICLE\"]))\n",
    "# IDs = [1,6,30,100007,100009,10001,100011,100014,100048,100054]\n",
    "def completeRecords(records):#records is a dataframe\n",
    "    records.TIME = pd.to_timedelta(records.TIME, unit=\"s\")\n",
    "    records.set_index([\"TIME\"],inplace=True)\n",
    "    records.loc[records.index[0]+pd.to_timedelta('24:00:00')]=records.iloc[0,:]\n",
    "    records.sort_index(inplace=True)\n",
    "    records = records.resample('30S').fillna(\"pad\")\n",
    "    records.drop([records.index[0]+pd.to_timedelta('24:00:00')],axis=0,inplace=True)\n",
    "    return records\n",
    "futures = []\n",
    "with concurrent.futures.ThreadPoolExecutor(max_workers=4) as executor:\n",
    "    for ID in userGroups.groups.keys():#userGroups.groups.keys(),IDs\n",
    "        futures.append(executor.submit(completeRecords, records=userGroups.get_group(ID)))\n",
    "    for future in concurrent.futures.as_completed(futures):\n",
    "        concatData = concatData.append(future.result())\n",
    "with open(\"completePLUdata_30sec.pickle\".format(a=savingLoc),\"wb\") as handle:\n",
    "          pickle.dump(snapDataNew,handle, protocol=pickle.HIGHEST_PROTOCOL )\n",
    "print((time.time() - startTime)//60,'minutes')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>VEHICLE</th>\n",
       "      <th>EASTING</th>\n",
       "      <th>NORTHING</th>\n",
       "      <th>mzr_id</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TIME</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0 days 06:30:00</th>\n",
       "      <td>1.0</td>\n",
       "      <td>632364.770972</td>\n",
       "      <td>5.816900e+06</td>\n",
       "      <td>7065.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0 days 06:30:30</th>\n",
       "      <td>1.0</td>\n",
       "      <td>632279.680941</td>\n",
       "      <td>5.816846e+06</td>\n",
       "      <td>5329.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0 days 06:31:00</th>\n",
       "      <td>1.0</td>\n",
       "      <td>632234.315601</td>\n",
       "      <td>5.816431e+06</td>\n",
       "      <td>5329.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0 days 06:31:30</th>\n",
       "      <td>1.0</td>\n",
       "      <td>632200.291596</td>\n",
       "      <td>5.816119e+06</td>\n",
       "      <td>5329.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0 days 06:32:00</th>\n",
       "      <td>1.0</td>\n",
       "      <td>632209.756236</td>\n",
       "      <td>5.815776e+06</td>\n",
       "      <td>5329.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1 days 05:17:00</th>\n",
       "      <td>100054.0</td>\n",
       "      <td>629786.783744</td>\n",
       "      <td>5.802847e+06</td>\n",
       "      <td>7514.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1 days 05:17:30</th>\n",
       "      <td>100054.0</td>\n",
       "      <td>629786.783744</td>\n",
       "      <td>5.802847e+06</td>\n",
       "      <td>7514.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1 days 05:18:00</th>\n",
       "      <td>100054.0</td>\n",
       "      <td>629786.783744</td>\n",
       "      <td>5.802847e+06</td>\n",
       "      <td>7514.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1 days 05:18:30</th>\n",
       "      <td>100054.0</td>\n",
       "      <td>629786.783744</td>\n",
       "      <td>5.802847e+06</td>\n",
       "      <td>7514.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1 days 05:19:00</th>\n",
       "      <td>100054.0</td>\n",
       "      <td>629786.783744</td>\n",
       "      <td>5.802847e+06</td>\n",
       "      <td>7514.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>28800 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  VEHICLE        EASTING      NORTHING  mzr_id\n",
       "TIME                                                          \n",
       "0 days 06:30:00       1.0  632364.770972  5.816900e+06  7065.0\n",
       "0 days 06:30:30       1.0  632279.680941  5.816846e+06  5329.0\n",
       "0 days 06:31:00       1.0  632234.315601  5.816431e+06  5329.0\n",
       "0 days 06:31:30       1.0  632200.291596  5.816119e+06  5329.0\n",
       "0 days 06:32:00       1.0  632209.756236  5.815776e+06  5329.0\n",
       "...                   ...            ...           ...     ...\n",
       "1 days 05:17:00  100054.0  629786.783744  5.802847e+06  7514.0\n",
       "1 days 05:17:30  100054.0  629786.783744  5.802847e+06  7514.0\n",
       "1 days 05:18:00  100054.0  629786.783744  5.802847e+06  7514.0\n",
       "1 days 05:18:30  100054.0  629786.783744  5.802847e+06  7514.0\n",
       "1 days 05:19:00  100054.0  629786.783744  5.802847e+06  7514.0\n",
       "\n",
       "[28800 rows x 4 columns]"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "concatData"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
