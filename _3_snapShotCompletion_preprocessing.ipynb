{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SnapShot preprocessing:\n",
    "In this notebook we get the MATSim snapShot output as the input. MATSim gives us the user location in constant intervals. It does not report anything when the user is not traveling. So to make this data as much as possible closer to the actual periodic location update, we have to fill in the empty records. also we initially get the snapshots every 30 seconds. For other polling intervals we only reduce the accuracy. Also for the spatial aggregation to the level os TAZ zones, we use arcGIS to extract the associated TAZ of each location record from the snapShot file. The output of arcGIS is the input here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### adding required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import time\n",
    "from math import floor\n",
    "import numpy as np\n",
    "import pickle\n",
    "import requests\n",
    "import concurrent.futures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### specifying the saving location "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "savingLoc = \"Y:/ZahraEftekhar/phase4/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### preparing the output of arcGIS for completion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output of GIS misses the locations outside of Amsterdam. Therefore, we complete the data by considering their TAZ code `0`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7481  records are missing that we refill them in our snapShot. \n"
     ]
    }
   ],
   "source": [
    "precompletion = pd.read_csv('{a}GISoutput_PreCompletion.CSV'.format(a=savingLoc),usecols=['mzr_id', 'VEHICLE','TIME','EASTING','NORTHING'])\n",
    "precompletion = precompletion.sort_values(by=[\"VEHICLE\",\"TIME\"])\n",
    "precompletion = precompletion.reset_index(drop=True)\n",
    "with open('{a}snapShot_allowedUsers.pickle'.format(a=savingLoc),'rb') as handle:\n",
    "    MATSimOutput = pickle.load(handle)\n",
    "MATSimOutput=MATSimOutput.reset_index(drop=False)\n",
    "print(len(MATSimOutput)-len(precompletion),\" records are missing that we refill them in our snapShot. \")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\programdata\\anaconda3\\envs\\extractingodfromxml\\lib\\site-packages\\ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "snapData = pd.merge(precompletion, MATSimOutput, how='right', on=['VEHICLE','TIME'])\n",
    "(snapData.mzr_id[snapData.mzr_id.isna()]) = 0\n",
    "snapData = snapData.loc[:,['VEHICLE','TIME','EASTING_y','NORTHING_y','mzr_id']]\n",
    "snapData.columns = ['VEHICLE', 'TIME', 'EASTING', 'NORTHING', 'mzr_id']\n",
    "snapData = snapData.sort_values(by = ['VEHICLE', 'TIME'])\n",
    "with open('{a}finalInputPython.pickle'.format(a=savingLoc),'wb') as handle:\n",
    "    pickle.dump(snapData, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, it is time to generate the complete snapShot data for every 30 seconds which represents the base data set even for generating other snapshots with different polling intervals (we resample from this data based on the specified polling interval)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>VEHICLE</th>\n",
       "      <th>TIME</th>\n",
       "      <th>EASTING</th>\n",
       "      <th>NORTHING</th>\n",
       "      <th>mzr_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>23400</td>\n",
       "      <td>632364.770972</td>\n",
       "      <td>5.816900e+06</td>\n",
       "      <td>7065.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>23430</td>\n",
       "      <td>632279.680941</td>\n",
       "      <td>5.816846e+06</td>\n",
       "      <td>5329.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>23460</td>\n",
       "      <td>632234.315601</td>\n",
       "      <td>5.816431e+06</td>\n",
       "      <td>5329.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>23490</td>\n",
       "      <td>632200.291596</td>\n",
       "      <td>5.816119e+06</td>\n",
       "      <td>5329.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>23520</td>\n",
       "      <td>632209.756236</td>\n",
       "      <td>5.815776e+06</td>\n",
       "      <td>5329.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   VEHICLE   TIME        EASTING      NORTHING  mzr_id\n",
       "0        1  23400  632364.770972  5.816900e+06  7065.0\n",
       "1        1  23430  632279.680941  5.816846e+06  5329.0\n",
       "2        1  23460  632234.315601  5.816431e+06  5329.0\n",
       "3        1  23490  632200.291596  5.816119e+06  5329.0\n",
       "4        1  23520  632209.756236  5.815776e+06  5329.0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('{a}finalInputPython.pickle'.format(a=savingLoc),'rb') as handle:\n",
    "    snapData = pickle.load(handle)\n",
    "snapData.reset_index(drop=True,inplace=True)\n",
    "snapData.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating snapshot file for 30 seconds polling interval:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 )       0.0009970664978027344\n",
      "1000 )       14.911331415176392\n",
      "2000 )       14.199820280075073\n",
      "3000 )       14.559810400009155\n",
      "4000 )       14.942324161529541\n",
      "5000 )       14.227362632751465\n",
      "6000 )       14.944886684417725\n",
      "7000 )       13.681585550308228\n",
      "8000 )       15.447866916656494\n",
      "9000 )       15.049609899520874\n",
      "10000 )       15.654713869094849\n",
      "11000 )       15.848775625228882\n",
      "12000 )       18.301263093948364\n",
      "13000 )       15.120662212371826\n",
      "14000 )       16.96431303024292\n",
      "15000 )       16.541218519210815\n",
      "16000 )       17.3521831035614\n",
      "17000 )       17.873571634292603\n",
      "18000 )       17.04734992980957\n",
      "19000 )       17.75270915031433\n",
      "20000 )       16.350047826766968\n",
      "21000 )       17.702622175216675\n",
      "22000 )       16.715301752090454\n",
      "5.0 minutes\n"
     ]
    }
   ],
   "source": [
    "#we time the process\n",
    "startTime = time.time()\n",
    "\n",
    "userGroups = (snapData.groupby([\"VEHICLE\"]))\n",
    "concatData = {}\n",
    "IDs = list(userGroups.groups.keys())[0:len(userGroups.groups.keys())]\n",
    "t1= time.time()\n",
    "for i,ID in enumerate(IDs): #userGroups.groups.keys()\n",
    "    \n",
    "    if i%1000==0: \n",
    "        print(i,\")      \",time.time()-t1)\n",
    "        t1= time.time()\n",
    "#     if (time.time()-t1>1): print(i,\") the id is:  \", ID)\n",
    "    \n",
    "    records=userGroups.get_group(ID)\n",
    "    records.TIME = pd.to_timedelta(records.TIME, unit=\"s\")\n",
    "    records.set_index([\"TIME\"],inplace=True)\n",
    "    # print(kk.tail())\n",
    "    records.loc[records.index[0]+pd.to_timedelta('24:00:00')]=records.iloc[0,:]\n",
    "    records.sort_index(inplace=True)\n",
    "    records = records.resample('30S').fillna(\"pad\")\n",
    "    records.drop([records.index[0]+pd.to_timedelta('24:00:00')],axis=0,inplace=True)\n",
    "    concatData[ID] = records\n",
    "#     t1= time.time()\n",
    "print((time.time() - startTime)//60,'minutes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"{a}completePLUdata_30sec_dict.pickle\".format(a=savingLoc),\"wb\") as handle:\n",
    "          pickle.dump(concatData,handle, protocol=pickle.HIGHEST_PROTOCOL )\n",
    "snapDataNew = pd.DataFrame()\n",
    "for ID in concatData.keys():\n",
    "    snapDataNew = snapDataNew.append(concatData[ID])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"{a}completePLUdata_30sec.pickle\".format(a=savingLoc),'wb') as handle:\n",
    "    pickle.dump(snapDataNew, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating snapshot file of polling intervals greater than 30 seconds: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So far, we have prepared the snapshot file with polling interval of 30 seconds. Now we use that as a base to generate the snapshot file of other polling intervals (using `resample`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "polling interval  30 :       1.0 minutes\n",
      "polling interval  60 :       0.0 minutes\n",
      "polling interval  300 :       0.0 minutes\n",
      "polling interval  600 :       0.0 minutes\n",
      "polling interval  900 :       0.0 minutes\n",
      "polling interval  1200 :       0.0 minutes\n",
      "polling interval  1500 :       0.0 minutes\n",
      "polling interval  1800 :       0.0 minutes\n",
      "polling interval  2100 :       0.0 minutes\n",
      "polling interval  2400 :       0.0 minutes\n",
      "polling interval  2700 :       0.0 minutes\n",
      "polling interval  3000 :       0.0 minutes\n",
      "polling interval  3300 :       0.0 minutes\n",
      "polling interval  3600 :       0.0 minutes\n",
      "polling interval  4500 :       0.0 minutes\n",
      "polling interval  5400 :       0.0 minutes\n",
      "polling interval  6300 :       0.0 minutes\n",
      "polling interval  7200 :       0.0 minutes\n",
      "9.0 minutes\n"
     ]
    }
   ],
   "source": [
    "#we time the process\n",
    "startTime = time.time()\n",
    "\n",
    "records.resample('120S').first()\n",
    "pollInt = [60,300,600,900,1200,1500,1800,2100,2400,2700,3000,3300,3600,4500,5400,6300,7200]\n",
    "IDs = list(concatData.keys())\n",
    "for interval in pollInt:\n",
    "    pollData = {}\n",
    "    t1= time.time()\n",
    "    for i,ID in enumerate(IDs): #userGroups.groups.keys()\n",
    "        records=concatData[ID]\n",
    "        records = records.resample('{b}S'.format(b=interval)).first()\n",
    "        pollData[ID] = records\n",
    "        if i==len(IDs)-1: \n",
    "            print(\"polling interval \",interval,\":      \",(time.time()-t1)//60,'minutes')\n",
    "            t1= time.time()\n",
    "    with open(\"{a}completePLUdata_{b}sec_dict.pickle\".format(a=savingLoc,b= interval),'wb') as handle:\n",
    "        pickle.dump(pollData, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "print((time.time() - startTime)//60,'minutes')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
