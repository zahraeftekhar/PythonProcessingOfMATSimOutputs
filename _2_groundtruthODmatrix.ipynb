{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f3aedcb2",
   "metadata": {},
   "source": [
    "# Estimation and Analysis of the ground-truth OD matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df9c88e4",
   "metadata": {},
   "source": [
    "#### adding required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "60dc51d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import time\n",
    "import sys\n",
    "# !conda install --yes --prefix {sys.prefix} pyproj\n",
    "# !{sys.executable} -m pip install geopandas\n",
    "from pyproj import Proj, transform\n",
    "from shapely.geometry import Point\n",
    "import geopandas as gpd\n",
    "import random\n",
    "from scipy.stats import gaussian_kde\n",
    "import datetime as dt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "192eea68",
   "metadata": {},
   "source": [
    "#### specifying the saving location "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c46e1cf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "savingLoc = \"Y:/ZahraEftekhar/phase4/\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "810b8506",
   "metadata": {},
   "source": [
    "#### functions for proximity analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7612e1cb",
   "metadata": {},
   "source": [
    "Here, we create classes and functions to automate the proximity analysis. These analyses include changing the coordinate system, mapping the location coordinates to their associated TAZ (traffic analysis zone)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7c25437a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#this class change coordinate system and map location coordinates to zones:\n",
    "class LongLat:\n",
    "    def __init__(self, *args):\n",
    "        self.TAZ = 0\n",
    "    def set_location(self, x, y):\n",
    "        from shapely.geometry import Point\n",
    "        self.location = Point(x, y)\n",
    "\n",
    "    def changeCoordSys(self, initial: str = 'epsg:23031', final: str = 'epsg:28992'):\n",
    "        from pyproj import Proj, transform\n",
    "        from shapely.geometry import Point\n",
    "        self.location = Point(transform(Proj(init=initial), Proj(init=final), self.location.x, self.location.y))\n",
    "\n",
    "    def zoneMapping(self, onepolygon, polygonName):\n",
    "        if (onepolygon.contains(self.location)):\n",
    "            self.TAZ = polygonName\n",
    "# this class only reads SHP:\n",
    "class TAZmap:\n",
    "    def __init__(self): pass\n",
    "\n",
    "    def set_map(self, value):\n",
    "        import geopandas as gpd\n",
    "        self.map = gpd.read_file(value).loc[:,['mzr_id','geometry']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "079bdb2b",
   "metadata": {},
   "source": [
    "#### building the zero OD Matrix based on the number of zones in the SHP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dafad35e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# building the zero OD Matrix based on the number of zones in the SHP\n",
    "map_mzr = TAZmap()\n",
    "map_mzr.set_map(\"{a}amsterdamMezuroZones.shp\".format(a=savingLoc))\n",
    "inputs = map_mzr.map.geometry\n",
    "amsterdamMezuroZones = pd.read_csv(\"{a}amsterdamMezuroZones.CSV\".format(a=savingLoc), usecols=['mzr_id'])\n",
    "tazNames = amsterdamMezuroZones['mzr_id']\n",
    "zoneZero = pd.Series(0)\n",
    "matrixRowColNames = tuple(zoneZero.append(tazNames))\n",
    "odsize=len(matrixRowColNames)\n",
    "del map_mzr\n",
    "ODMatrix_df = pd.DataFrame(np.zeros((odsize, odsize), dtype=np.int32), columns=matrixRowColNames,\n",
    "                           index=matrixRowColNames)  # creating empty OD matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9bd9bc9",
   "metadata": {},
   "source": [
    "## Specifying the OD matrix estimation interval\n",
    "========================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "4f61f168",
   "metadata": {},
   "outputs": [],
   "source": [
    "ODstart = \"06:30:00\"\n",
    "ODend = \"09:30:00\"\n",
    "startTime_OD = pd.to_timedelta(ODstart)\n",
    "endTime_OD = pd.to_timedelta(ODend)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51da44ba",
   "metadata": {},
   "source": [
    "#### Reading the travel diaries to estimate the OD matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "60e03f49",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('{a}1.trueLocExperienced.pickle'.format(a=savingLoc), 'rb') as handle:\n",
    "    itemlistExperienced = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5edbb8c4",
   "metadata": {},
   "source": [
    "======================================================================================================"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67d26d0d",
   "metadata": {},
   "source": [
    "#### estimating the ground-truth OD matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dad8f77",
   "metadata": {},
   "outputs": [],
   "source": [
    "#we time the process\n",
    "startTime = time.time()\n",
    "for ID in itemlistExperienced.keys():#itemlistExperienced.keys() or ['100158'] or ['100048']\n",
    "    activityListExperienced = itemlistExperienced[ID]\n",
    "    activityListExperienced.loc[:,\"end\"].iloc[-1] = pd.to_timedelta(activityListExperienced.loc[:,\"end\"].iloc[-1]\n",
    "                                                                  )+ pd.to_timedelta('24:00:00')\n",
    "    j=1\n",
    "    while j < len(np.arange(len(activityListExperienced))):\n",
    "        if j==len(np.arange(len(activityListExperienced)))-1:\n",
    "            start_time1 = pd.to_timedelta((activityListExperienced.loc[:,\"start\"]).iloc[j])\n",
    "            end_time1 = pd.to_timedelta((activityListExperienced.loc[:,\"end\"]).iloc[j])\n",
    "            start_time2 = pd.to_timedelta((activityListExperienced.loc[:,\"start\"]).iloc[0])+ pd.to_timedelta('24:00:00')\n",
    "            endActivity = end_time1\n",
    "            startNewActivity = start_time2\n",
    "            if pd.to_timedelta('23:59:59')>=pd.to_timedelta(ODstart)>=pd.to_timedelta(start_time1):\n",
    "                startTime_OD = pd.to_timedelta(ODstart)\n",
    "            else:\n",
    "                startTime_OD = pd.to_timedelta(ODstart) + pd.to_timedelta('24:00:00')\n",
    "            if pd.to_timedelta('23:59:59')>= pd.to_timedelta(ODend) >=pd.to_timedelta(start_time1):\n",
    "                endTime_OD =pd.to_timedelta(ODend)\n",
    "            else:\n",
    "                endTime_OD = pd.to_timedelta(ODend)+ pd.to_timedelta('24:00:00')\n",
    "        else:\n",
    "            start_time1 = pd.to_timedelta(activityListExperienced.loc[:,\"start\"].iloc[j])\n",
    "            end_time1 = pd.to_timedelta(activityListExperienced.loc[:,\"end\"].iloc[j])\n",
    "            start_time2 = pd.to_timedelta(activityListExperienced.loc[:,\"start\"].iloc[j+1])\n",
    "            endActivity = end_time1 \n",
    "            startNewActivity = start_time2 \n",
    "        if pd.to_timedelta(start_time1) <= pd.to_timedelta(startTime_OD) < pd.to_timedelta(startNewActivity):\n",
    "            if endTime_OD <= endActivity:\n",
    "                break\n",
    "            else:\n",
    "                while pd.to_timedelta(endTime_OD) > pd.to_timedelta(endActivity):\n",
    "                    point1 = LongLat()\n",
    "                    point1.set_location(x=float(activityListExperienced.loc[:,\"x\"].iloc[j]),\n",
    "                                        y=float(activityListExperienced.loc[:,\"y\"].iloc[j]))#*********ghablan:j-1\n",
    "                    point1.changeCoordSys()\n",
    "                    for k in range(len(tazNames)):\n",
    "                        point1.zoneMapping(inputs[k], tazNames[k])\n",
    "                    origin = point1.TAZ\n",
    "                    point2 = LongLat()\n",
    "                    if j == len(activityListExperienced) - 1:\n",
    "                        point2.set_location(x=float(activityListExperienced.loc[:,\"x\"].iloc[0]),\n",
    "                                            y=float(activityListExperienced.loc[:,\"y\"].iloc[0]))\n",
    "                    else:\n",
    "                        point2.set_location(x=float(activityListExperienced.loc[:,\"x\"].iloc[j+1]),\n",
    "                                        y=float(activityListExperienced.loc[:,\"y\"].iloc[j+1])) #*****ghablan: j\n",
    "                    point2.changeCoordSys()\n",
    "                    for k in range(len(tazNames)):\n",
    "                        point2.zoneMapping(inputs[k], tazNames[k])\n",
    "                    destination = point2.TAZ\n",
    "                    ODMatrix_df[origin][destination] = ODMatrix_df[origin][destination] + 1\n",
    "                    j += 1\n",
    "                    if j > len(np.arange(len(activityListExperienced))) - 1: break\n",
    "                    if j== len(np.arange(len(activityListExperienced)))-1:\n",
    "                        end_time1 = pd.to_timedelta((activityListExperienced.loc[:,\"end\"]).iloc[0])+ pd.to_timedelta('24:00:00')\n",
    "                    else:\n",
    "                        end_time1 = pd.to_timedelta((activityListExperienced.loc[:,\"end\"]).iloc[j])\n",
    "                    endActivity = end_time1\n",
    "                break\n",
    "        j += 1\n",
    "TXTFileName = \"{a}OD({start1}-{start2}_{end1}-{end2}).pickle\".format(a=savingLoc,start1 = ODstart[0:2],\n",
    "                                                                                     start2 = ODstart[3:5],\n",
    "                                                                     end1 = ODend[0:2], end2 = ODend[3:5])\n",
    "with open(TXTFileName, 'wb') as handle:\n",
    "    pickle.dump(ODMatrix_df, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "print((time.time() - startTime)//60,'minutes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "c36c2b1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11948\n"
     ]
    }
   ],
   "source": [
    "print(np.sum(np.sum(ODMatrix_df, axis=0)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "758a5886",
   "metadata": {},
   "source": [
    "================================================================================\n",
    "### creating a `dict` file of all the trips that each user has in its travel diaries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "299bb66e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>VEHICLE</th>\n",
       "      <th>activityType</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>work</td>\n",
       "      <td>629393.6676188618</td>\n",
       "      <td>5803949.115843206</td>\n",
       "      <td>06:52:04</td>\n",
       "      <td>16:49:20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>home</td>\n",
       "      <td>632315.3322837545</td>\n",
       "      <td>5817000.086435355</td>\n",
       "      <td>17:10:47</td>\n",
       "      <td>06:29:59</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  VEHICLE activityType                  x                  y     start  \\\n",
       "0       1         work  629393.6676188618  5803949.115843206  06:52:04   \n",
       "0       1         home  632315.3322837545  5817000.086435355  17:10:47   \n",
       "\n",
       "        end  \n",
       "0  16:49:20  \n",
       "0  06:29:59  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "itemlistExperienced[\"1\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "270dbc7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\programdata\\anaconda3\\envs\\extractingodfromxml\\lib\\site-packages\\pandas\\core\\indexing.py:670: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_with_indexer(indexer, value)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0 minutes\n"
     ]
    }
   ],
   "source": [
    "#we time the process\n",
    "startTime = time.time()\n",
    "\n",
    "trips = {}\n",
    "for ID in itemlistExperienced.keys():\n",
    "    activities= itemlistExperienced[ID]\n",
    "    activities.columns = [\"VEHICLE\",\"activityType\",\"x\",\"y\",\"A_start\",\"A_end\"]\n",
    "    activities[\"start\"] = 0\n",
    "    activities[\"duration\"] = 0\n",
    "    \n",
    "    for j in np.arange(0,len(activities)):\n",
    "            activities.loc[:,\"start\"].iloc[j] = pd.to_timedelta(activities.loc[:,\"A_end\"].iloc[j-1])\n",
    "            activities.loc[:,\"duration\"].iloc[j]=pd.to_timedelta(activities.loc[:,\"A_start\"].iloc[j])-pd.to_timedelta(activities.loc[:,\"A_end\"].iloc[j-1])\n",
    "    activities.drop([\"activityType\",\"x\",\"y\",\"A_start\",\"A_end\"],axis=1,inplace=True)\n",
    "    trips[ID] = activities\n",
    "TXTFileName = \"{a}trips.pickle\".format(a=savingLoc)\n",
    "with open(TXTFileName, 'wb') as handle:\n",
    "    pickle.dump(trips, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "print((time.time() - startTime)//60,'minutes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "2ade7447",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>VEHICLE</th>\n",
       "      <th>start</th>\n",
       "      <th>duration</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0 days 06:29:59</td>\n",
       "      <td>0 days 00:22:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0 days 16:49:20</td>\n",
       "      <td>0 days 00:21:27</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  VEHICLE            start         duration\n",
       "0       1  0 days 06:29:59  0 days 00:22:05\n",
       "0       1  0 days 16:49:20  0 days 00:21:27"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trips[\"1\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e9e9432",
   "metadata": {},
   "source": [
    "### analysis of the ground truth location and activity type identification:\n",
    "Here, we use Bayesian Theory to compute the probability of each even and activity, then infer the category depending on the temporal characteristics of each record (i.e starting time and duration). Remmember, we have to include Mezuro zone id instead of location coordinates to represent the spatial aggregation due to the fact that in empirical data the BTS location is reported, NOT the user's location. This only means that the diagonal of the OD matrix becomes zero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7e75e79a",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('{a}1.trueLocExperienced.pickle'.format(a=savingLoc), 'rb') as handle:\n",
    "    activities = pickle.load(handle)\n",
    "for ID in activities.keys():\n",
    "    activities[ID].loc[:,\"end\"].iloc[-1] = pd.to_timedelta(activities[ID].loc[:,\"end\"].iloc[-1]\n",
    "                                                                  )+ pd.to_timedelta('24:00:00')\n",
    "    activities[ID].loc[:,\"duration\"] =  pd.to_timedelta(activities[ID].loc[:,\"end\"])-pd.to_timedelta(activities[ID].loc[:,\"start\"])\n",
    "#this file is the same as `1.trueLocExperienced.pickle` except that it also includes the duration of activities\n",
    "TXTFileName = \"{a}activities.pickle\".format(a=savingLoc)\n",
    "with open(TXTFileName, 'wb') as handle:\n",
    "    pickle.dump(activities, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "df86c453",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"{a}trips.pickle\".format(a=savingLoc),'rb') as handle:\n",
    "    trips = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a12b55fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#generating dataframe of trips and activities for the ease of operations and visualizability\n",
    "activity_df = pd.DataFrame()\n",
    "trip_df = pd.DataFrame()\n",
    "for ID in activities.keys():\n",
    "    activity_df = activity_df.append(activities[ID])\n",
    "    trip_df = trip_df.append(trips[ID])\n",
    "activity_df.reset_index(drop=True,inplace=True)\n",
    "trip_df.reset_index(drop=True,inplace=True)\n",
    "with open('{a}activity_df.pickle'.format(a=savingLoc), 'wb') as handle:\n",
    "    pickle.dump(activity_df, handle, protocol=pickle.HIGHEST_PROTOCOL)    \n",
    "with open('{a}trip_df.pickle'.format(a=savingLoc), 'wb') as handle:\n",
    "    pickle.dump(trip_df, handle, protocol=pickle.HIGHEST_PROTOCOL)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "6acb71d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>VEHICLE</th>\n",
       "      <th>activityType</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>duration</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>work</td>\n",
       "      <td>629393.6676188618</td>\n",
       "      <td>5803949.115843206</td>\n",
       "      <td>06:52:04</td>\n",
       "      <td>16:49:20</td>\n",
       "      <td>09:57:16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>home</td>\n",
       "      <td>632315.3322837545</td>\n",
       "      <td>5817000.086435355</td>\n",
       "      <td>17:10:47</td>\n",
       "      <td>1 days 06:29:59</td>\n",
       "      <td>13:19:12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10</td>\n",
       "      <td>work</td>\n",
       "      <td>627192.4415982522</td>\n",
       "      <td>5799465.4065392725</td>\n",
       "      <td>06:01:34</td>\n",
       "      <td>15:27:02</td>\n",
       "      <td>09:25:28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10</td>\n",
       "      <td>home</td>\n",
       "      <td>632315.3322837545</td>\n",
       "      <td>5817000.086435355</td>\n",
       "      <td>15:54:40</td>\n",
       "      <td>1 days 05:35:01</td>\n",
       "      <td>13:40:21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100007</td>\n",
       "      <td>work</td>\n",
       "      <td>634456.1049276257</td>\n",
       "      <td>5793373.482339734</td>\n",
       "      <td>06:32:44</td>\n",
       "      <td>15:59:53</td>\n",
       "      <td>09:27:09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  VEHICLE activityType                  x                   y     start  \\\n",
       "0       1         work  629393.6676188618   5803949.115843206  06:52:04   \n",
       "1       1         home  632315.3322837545   5817000.086435355  17:10:47   \n",
       "2      10         work  627192.4415982522  5799465.4065392725  06:01:34   \n",
       "3      10         home  632315.3322837545   5817000.086435355  15:54:40   \n",
       "4  100007         work  634456.1049276257   5793373.482339734  06:32:44   \n",
       "\n",
       "               end duration  \n",
       "0         16:49:20 09:57:16  \n",
       "1  1 days 06:29:59 13:19:12  \n",
       "2         15:27:02 09:25:28  \n",
       "3  1 days 05:35:01 13:40:21  \n",
       "4         15:59:53 09:27:09  "
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "activity_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3bd11ba",
   "metadata": {},
   "source": [
    "Now, we generate __training sets__ from trips and activities. This includes the trips and activity of 1% of the users. each training record is the label, duration and starting time of that event/activity. Then we use the entire data as the __test set__ to identify the location/activity category. The location category is either `stay`(activity) or `pass-by`(trip). The activity categories are either `home`, `work` or `other`. In this step we compute the identification accuracy which is the number of correctly identified calss devided by the number of each class. For instance we compute `home` identification accuracy as follows:\n",
    "$a = \\frac{true-positive-`home`}{actual-number-`home`s } $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c148f71c",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('{a}activity_df.pickle'.format(a=savingLoc), 'rb') as handle:\n",
    "    activities = pickle.load(handle)\n",
    "with open(\"{a}trip_df.pickle\".format(a=savingLoc), 'rb') as handle:\n",
    "    trips = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "24780bbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\programdata\\anaconda3\\envs\\extractingodfromxml\\lib\\site-packages\\ipykernel_launcher.py:84: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "c:\\programdata\\anaconda3\\envs\\extractingodfromxml\\lib\\site-packages\\ipykernel_launcher.py:90: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "c:\\programdata\\anaconda3\\envs\\extractingodfromxml\\lib\\site-packages\\ipykernel_launcher.py:96: RuntimeWarning: divide by zero encountered in log\n",
      "c:\\programdata\\anaconda3\\envs\\extractingodfromxml\\lib\\site-packages\\ipykernel_launcher.py:96: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "c:\\programdata\\anaconda3\\envs\\extractingodfromxml\\lib\\site-packages\\ipykernel_launcher.py:98: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "c:\\programdata\\anaconda3\\envs\\extractingodfromxml\\lib\\site-packages\\ipykernel_launcher.py:124: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "c:\\programdata\\anaconda3\\envs\\extractingodfromxml\\lib\\site-packages\\ipykernel_launcher.py:130: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "c:\\programdata\\anaconda3\\envs\\extractingodfromxml\\lib\\site-packages\\ipykernel_launcher.py:136: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "c:\\programdata\\anaconda3\\envs\\extractingodfromxml\\lib\\site-packages\\ipykernel_launcher.py:138: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "c:\\programdata\\anaconda3\\envs\\extractingodfromxml\\lib\\site-packages\\ipykernel_launcher.py:146: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "c:\\programdata\\anaconda3\\envs\\extractingodfromxml\\lib\\site-packages\\ipykernel_launcher.py:152: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "c:\\programdata\\anaconda3\\envs\\extractingodfromxml\\lib\\site-packages\\ipykernel_launcher.py:158: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "c:\\programdata\\anaconda3\\envs\\extractingodfromxml\\lib\\site-packages\\ipykernel_launcher.py:160: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.0 minutes\n"
     ]
    }
   ],
   "source": [
    "#we time the process\n",
    "startTime = time.time()\n",
    "\n",
    "# _______________test seed based on user sampling _________________________________\n",
    "seedSet = np.arange(101,151)\n",
    "sensitivityTable = pd.DataFrame(index=seedSet)\n",
    "sensitivityTable.index=seedSet\n",
    "for s, seed in enumerate(seedSet):\n",
    "    ids = pd.unique(activities.VEHICLE)\n",
    "    random.seed(seed)\n",
    "    indices = random.sample(range(len(ids)),round(.01*len(ids))) #1% sampling of users\n",
    "    indices = pd.DataFrame(indices, columns=[\"VEHICLE\"])\n",
    "    trainIDs =pd.DataFrame(ids[indices])\n",
    "    trainIDs.columns = [\"VEHICLE\"]\n",
    "    trainingSet_trips = (trainIDs.merge(trips, on=[\"VEHICLE\"], how=\"inner\", sort=True,validate=\"1:m\"))\n",
    "    trainingSet_activities = (trainIDs.merge(activities, on=[\"VEHICLE\"], how=\"inner\", sort=True,validate=\"1:m\"))\n",
    "    with open('{a}/trainingActivity_seed{s}.pickle'.format(a=savingLoc,s=seed), 'wb') as handle:\n",
    "        pickle.dump(trainingSet_activities, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    with open('{a}trainingTrip_seed{s}.pickle'.format(a=savingLoc,s=seed), 'wb') as handle:\n",
    "        pickle.dump(trainingSet_trips, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "\n",
    "    trainingSet_home = trainingSet_activities[trainingSet_activities.activityType == \"home\"]\n",
    "    trainingSet_work = trainingSet_activities[trainingSet_activities.activityType == \"work\"]\n",
    "    trainingSet_other = trainingSet_activities[(trainingSet_activities.activityType != \"home\") & (trainingSet_activities.activityType != \"work\")]\n",
    "    trainingSet_home.to_csv(\"{a}trainingHome_seed{s}.CSV\".format(a=savingLoc,s=seed),index=False,header=True)\n",
    "    trainingSet_work.to_csv(\"{a}trainingWork_seed{s}.CSV\".format(a=savingLoc,s=seed),index=False,header=True)\n",
    "    trainingSet_other.to_csv(\"{a}trainingOther_seed{s}.CSV\".format(a=savingLoc,s=seed),index=False,header=True)\n",
    "\n",
    "    with open('{a}trainingHome_seed{s}.pickle'.format(a=savingLoc,s=seed), 'wb') as handle:\n",
    "        pickle.dump(trainingSet_home, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    with open('{a}trainingWork_seed{s}.pickle'.format(a=savingLoc,s=seed), 'wb') as handle:\n",
    "        pickle.dump(trainingSet_work, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    with open('{a}trainingOther_seed{s}.pickle'.format(a=savingLoc,s=seed), 'wb') as handle:\n",
    "        pickle.dump(trainingSet_other, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    # ________________________________________________________________________________________\n",
    "    # ****************************************************************************************\n",
    "    home = activities[activities.activityType== \"home\"]\n",
    "    work = activities[activities.activityType== \"work\"]\n",
    "    other = activities[(activities.activityType != \"home\") & (activities.activityType != \"work\")]\n",
    "    # ****************************************************************************************\n",
    "    # ________________________ writing data: Trainset _________________________\n",
    "\n",
    "    # ________________________________________________________________\n",
    "\n",
    "    # ___________________________ Probability calculations_________________________________________\n",
    "    #***************************************************************************\n",
    "    prior_activity = len(activities)/(len(activities) + len(trips))\n",
    "    prior_trip =  len(trips)/(len(activities) + len(trips))\n",
    "    activities['activity?'] = np.log(prior_trip+((gaussian_kde((\n",
    "        pd.to_timedelta(trainingSet_trips.start)).dt.total_seconds()).pdf((\n",
    "        pd.to_timedelta(activities.start)).dt.total_seconds())))+((gaussian_kde(\n",
    "        (pd.to_timedelta(trainingSet_trips.duration)).dt.total_seconds()).pdf((\n",
    "        pd.to_timedelta(activities.duration)).dt.total_seconds()))))<=np.log(prior_activity+((gaussian_kde((\n",
    "        pd.to_timedelta(trainingSet_activities.start)).dt.total_seconds()).pdf((\n",
    "        pd.to_timedelta(activities.start)).dt.total_seconds())))+((gaussian_kde(\n",
    "        (pd.to_timedelta(trainingSet_activities.duration)).dt.total_seconds()).pdf((\n",
    "        pd.to_timedelta(activities.duration)).dt.total_seconds()))))\n",
    "    sensitivityTable.loc[seed,\"stay accuracy\"] = sum(activities['activity?'])/len(activities)\n",
    "\n",
    "    #***************************************************************************\n",
    "    trips['trip?'] = np.log(prior_trip+((gaussian_kde((\n",
    "        pd.to_timedelta(trainingSet_trips.start)).dt.total_seconds()).pdf((\n",
    "        pd.to_timedelta(trips.start)).dt.total_seconds())))+((gaussian_kde(\n",
    "        (pd.to_timedelta(trainingSet_trips.duration)).dt.total_seconds()).pdf((\n",
    "        pd.to_timedelta(trips.duration)).dt.total_seconds()))))>=np.log(prior_activity+((gaussian_kde((\n",
    "        pd.to_timedelta(trainingSet_activities.start)).dt.total_seconds()).pdf((\n",
    "        pd.to_timedelta(trips.start)).dt.total_seconds())))+((gaussian_kde(\n",
    "        (pd.to_timedelta(trainingSet_activities.duration)).dt.total_seconds()).pdf((\n",
    "        pd.to_timedelta(trips.duration)).dt.total_seconds()))))\n",
    "    sensitivityTable.loc[seed,\"pass-by accuracy\"] = sum(trips['trip?'])/len(trips)\n",
    "\n",
    "\n",
    "    #***************************************************************************\n",
    "\n",
    "    prior_home = len(trainingSet_home)/(len(trainingSet_home) + len(trainingSet_work) + len(trainingSet_other))\n",
    "    prior_work =  len(trainingSet_work)/(len(trainingSet_home) + len(trainingSet_work) + len(trainingSet_other))\n",
    "    prior_other = len(trainingSet_other)/(len(trainingSet_home) + len(trainingSet_work) + len(trainingSet_other))\n",
    "\n",
    "    home['home'] = np.log(prior_home)+np.log(((gaussian_kde((\n",
    "        pd.to_timedelta(trainingSet_home.start)).dt.total_seconds()).pdf((\n",
    "        pd.to_timedelta(home.start)).dt.total_seconds()))))+np.log(((gaussian_kde(\n",
    "        (pd.to_timedelta(trainingSet_home.duration)).dt.total_seconds()).pdf((\n",
    "        pd.to_timedelta(home.duration)).dt.total_seconds()))))\n",
    "\n",
    "    home['work'] = np.log(prior_work)+np.log(((gaussian_kde((\n",
    "        pd.to_timedelta(trainingSet_work.start)).dt.total_seconds()).pdf((\n",
    "        pd.to_timedelta(home.start)).dt.total_seconds()))))+np.log(((gaussian_kde(\n",
    "        (pd.to_timedelta(trainingSet_work.duration)).dt.total_seconds()).pdf((\n",
    "        pd.to_timedelta(home.duration)).dt.total_seconds()))))\n",
    "\n",
    "    home['other'] = np.log(prior_other)+np.log(((gaussian_kde((\n",
    "        pd.to_timedelta(trainingSet_other.start)).dt.total_seconds()).pdf((\n",
    "        pd.to_timedelta(home.start)).dt.total_seconds()))))+np.log(((gaussian_kde(\n",
    "        (pd.to_timedelta(trainingSet_other.duration)).dt.total_seconds()).pdf((\n",
    "        pd.to_timedelta(home.duration)).dt.total_seconds()))))\n",
    "\n",
    "    home['activity?'] = home[['home','work','other']].idxmax(axis=1)\n",
    "#     (np.log(prior_home+((gaussian_kde((\n",
    "#         pd.to_timedelta(trainingSet_home.start)).dt.total_seconds()).pdf((\n",
    "#         pd.to_timedelta(home.start)).dt.total_seconds())))+((gaussian_kde(\n",
    "#         (pd.to_timedelta(trainingSet_trips.duration)).dt.total_seconds()).pdf((\n",
    "#         pd.to_timedelta(home.duration)).dt.total_seconds()))))>=np.log(prior_work+((gaussian_kde((\n",
    "#         pd.to_timedelta(trainingSet_work.start)).dt.total_seconds()).pdf((\n",
    "#         pd.to_timedelta(home.start)).dt.total_seconds())))+((gaussian_kde(\n",
    "#         (pd.to_timedelta(trainingSet_work.duration)).dt.total_seconds()).pdf((\n",
    "#         pd.to_timedelta(home.duration)).dt.total_seconds()))))) &(np.log(prior_home+((gaussian_kde((\n",
    "#         pd.to_timedelta(trainingSet_home.start)).dt.total_seconds()).pdf((\n",
    "#         pd.to_timedelta(home.start)).dt.total_seconds())))+((gaussian_kde(\n",
    "#         (pd.to_timedelta(trainingSet_home.duration)).dt.total_seconds()).pdf((\n",
    "#         pd.to_timedelta(home.duration)).dt.total_seconds()))))>=np.log(prior_other+((gaussian_kde((\n",
    "#         pd.to_timedelta(trainingSet_other.start)).dt.total_seconds()).pdf((\n",
    "#         pd.to_timedelta(home.start)).dt.total_seconds())))+((gaussian_kde(\n",
    "#         (pd.to_timedelta(trainingSet_other.duration)).dt.total_seconds()).pdf((\n",
    "#         pd.to_timedelta(home.duration)).dt.total_seconds())))))\n",
    "    sensitivityTable.loc[seed,\"home accuracy\"] = sum(home['activity?']==\"home\")/len(home)\n",
    "\n",
    "\n",
    "#***************************************************************************\n",
    "    work['home'] = np.log(prior_home)+np.log(((gaussian_kde((\n",
    "        pd.to_timedelta(trainingSet_home.start)).dt.total_seconds()).pdf((\n",
    "        pd.to_timedelta(work.start)).dt.total_seconds()))))+np.log(((gaussian_kde(\n",
    "        (pd.to_timedelta(trainingSet_home.duration)).dt.total_seconds()).pdf((\n",
    "        pd.to_timedelta(work.duration)).dt.total_seconds()))))\n",
    "\n",
    "    work['work'] = np.log(prior_work)+np.log(((gaussian_kde((\n",
    "        pd.to_timedelta(trainingSet_work.start)).dt.total_seconds()).pdf((\n",
    "        pd.to_timedelta(work.start)).dt.total_seconds()))))+np.log(((gaussian_kde(\n",
    "        (pd.to_timedelta(trainingSet_work.duration)).dt.total_seconds()).pdf((\n",
    "        pd.to_timedelta(work.duration)).dt.total_seconds()))))\n",
    "\n",
    "    work['other'] = np.log(prior_other)+np.log(((gaussian_kde((\n",
    "        pd.to_timedelta(trainingSet_other.start)).dt.total_seconds()).pdf((\n",
    "        pd.to_timedelta(work.start)).dt.total_seconds()))))+np.log(((gaussian_kde(\n",
    "        (pd.to_timedelta(trainingSet_other.duration)).dt.total_seconds()).pdf((\n",
    "        pd.to_timedelta(work.duration)).dt.total_seconds()))))\n",
    "\n",
    "    work['activity?'] = work[['home','work','other']].idxmax(axis=1)\n",
    "    sensitivityTable.loc[seed,\"work accuracy\"] = sum(work['activity?']==\"work\")/len(work)\n",
    "\n",
    "#***************************************************************************\n",
    "    other['home'] = np.log(prior_home)+np.log(((gaussian_kde((\n",
    "        pd.to_timedelta(trainingSet_home.start)).dt.total_seconds()).pdf((\n",
    "        pd.to_timedelta(other.start)).dt.total_seconds()))))+np.log(((gaussian_kde(\n",
    "        (pd.to_timedelta(trainingSet_home.duration)).dt.total_seconds()).pdf((\n",
    "        pd.to_timedelta(other.duration)).dt.total_seconds()))))\n",
    "\n",
    "    other['work'] = np.log(prior_work)+np.log(((gaussian_kde((\n",
    "        pd.to_timedelta(trainingSet_work.start)).dt.total_seconds()).pdf((\n",
    "        pd.to_timedelta(other.start)).dt.total_seconds()))))+np.log(((gaussian_kde(\n",
    "        (pd.to_timedelta(trainingSet_work.duration)).dt.total_seconds()).pdf((\n",
    "        pd.to_timedelta(other.duration)).dt.total_seconds()))))\n",
    "\n",
    "    other['other'] = np.log(prior_other)+np.log(((gaussian_kde((\n",
    "        pd.to_timedelta(trainingSet_other.start)).dt.total_seconds()).pdf((\n",
    "        pd.to_timedelta(other.start)).dt.total_seconds()))))+np.log(((gaussian_kde(\n",
    "        (pd.to_timedelta(trainingSet_other.duration)).dt.total_seconds()).pdf((\n",
    "        pd.to_timedelta(other.duration)).dt.total_seconds()))))\n",
    "\n",
    "    other['activity?'] = other[['home','work','other']].idxmax(axis=1)\n",
    "    sensitivityTable.loc[seed,\"other accuracy\"] = sum(other['activity?']==\"other\")/len(other)\n",
    "\n",
    "#     ***************************************************************************\n",
    "    home.to_csv(\"{a}home_seed{s}.CSV\".format(a=savingLoc,s=seed),index=False,header=True)\n",
    "    work.to_csv(\"{a}work_seed{s}.CSV\".format(a=savingLoc,s=seed),index=False,header=True)\n",
    "    other.to_csv(\"{a}other_seed{s}.CSV\".format(a=savingLoc,s=seed),index=False,header=True)\n",
    "\n",
    "    with open('{a}home_seed{s}.pickle'.format(a=savingLoc,s=seed), 'wb') as handle:\n",
    "        pickle.dump(home, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    with open('{a}work_seed{s}.pickle'.format(a=savingLoc,s=seed), 'wb') as handle:\n",
    "        pickle.dump(work, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    with open('{a}other_seed{s}.pickle'.format(a=savingLoc,s=seed), 'wb') as handle:\n",
    "        pickle.dump(other, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "sensitivityTable.to_excel(\"{a}userSampling_onePercentLocationDetectionSensitivity.xlsx\".format(a=savingLoc), header=True,\n",
    "                          index=True)\n",
    "print((time.time() - startTime)//60,'minutes')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9086a9f",
   "metadata": {},
   "source": [
    "# Appendix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b1f76f0",
   "metadata": {},
   "source": [
    "Generating training sets with different proportionality:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "72a7550a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>VEHICLE</th>\n",
       "      <th>activityType</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>duration</th>\n",
       "      <th>geometry</th>\n",
       "      <th>mzr_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10001</td>\n",
       "      <td>work</td>\n",
       "      <td>626348.5794967742</td>\n",
       "      <td>5803352.505475129</td>\n",
       "      <td>07:13:11</td>\n",
       "      <td>16:43:03</td>\n",
       "      <td>0 days 09:29:52</td>\n",
       "      <td>POINT (118699.985 486367.588)</td>\n",
       "      <td>7512.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10001</td>\n",
       "      <td>home</td>\n",
       "      <td>625308.5056096063</td>\n",
       "      <td>5792622.8888017945</td>\n",
       "      <td>17:00:03</td>\n",
       "      <td>1 days 06:57:56</td>\n",
       "      <td>0 days 13:57:53</td>\n",
       "      <td>POINT (117306.649 475676.791)</td>\n",
       "      <td>7831.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100089</td>\n",
       "      <td>sozializing</td>\n",
       "      <td>618591.4587132754</td>\n",
       "      <td>5793162.677454361</td>\n",
       "      <td>20:38:36</td>\n",
       "      <td>22:06:11</td>\n",
       "      <td>0 days 01:27:35</td>\n",
       "      <td>POINT (110610.135 476437.663)</td>\n",
       "      <td>5601.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100089</td>\n",
       "      <td>home</td>\n",
       "      <td>630028.7167090132</td>\n",
       "      <td>5802955.596728954</td>\n",
       "      <td>22:27:16</td>\n",
       "      <td>1 days 20:20:51</td>\n",
       "      <td>0 days 21:53:35</td>\n",
       "      <td>POINT (122365.447 485849.465)</td>\n",
       "      <td>7514.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100294</td>\n",
       "      <td>sozializing</td>\n",
       "      <td>638653.6948047496</td>\n",
       "      <td>5796600.87829093</td>\n",
       "      <td>17:39:24</td>\n",
       "      <td>21:39:14</td>\n",
       "      <td>0 days 03:59:50</td>\n",
       "      <td>POINT (130776.988 479213.242)</td>\n",
       "      <td>5013.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>100294</td>\n",
       "      <td>home</td>\n",
       "      <td>630543.4389452781</td>\n",
       "      <td>5803946.491865685</td>\n",
       "      <td>21:53:42</td>\n",
       "      <td>1 days 17:23:16</td>\n",
       "      <td>0 days 19:29:34</td>\n",
       "      <td>POINT (122912.629 486822.948)</td>\n",
       "      <td>7510.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>10052</td>\n",
       "      <td>work</td>\n",
       "      <td>612307.6747723853</td>\n",
       "      <td>5798999.945285048</td>\n",
       "      <td>08:33:46</td>\n",
       "      <td>11:39:57</td>\n",
       "      <td>0 days 03:06:11</td>\n",
       "      <td>POINT (104521.162 482479.773)</td>\n",
       "      <td>5597.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>10052</td>\n",
       "      <td>business</td>\n",
       "      <td>623442.6951386724</td>\n",
       "      <td>5793243.906416614</td>\n",
       "      <td>12:00:45</td>\n",
       "      <td>12:25:12</td>\n",
       "      <td>0 days 00:24:27</td>\n",
       "      <td>POINT (115462.079 476359.022)</td>\n",
       "      <td>7831.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>10052</td>\n",
       "      <td>business</td>\n",
       "      <td>627451.4732033794</td>\n",
       "      <td>5800136.966645968</td>\n",
       "      <td>12:37:54</td>\n",
       "      <td>12:59:37</td>\n",
       "      <td>0 days 00:21:43</td>\n",
       "      <td>POINT (119696.366 483117.047)</td>\n",
       "      <td>7513.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10052</td>\n",
       "      <td>shoppingND</td>\n",
       "      <td>623803.4218678667</td>\n",
       "      <td>5806163.850149635</td>\n",
       "      <td>13:11:05</td>\n",
       "      <td>13:37:23</td>\n",
       "      <td>0 days 00:26:18</td>\n",
       "      <td>POINT (116248.638 489261.716)</td>\n",
       "      <td>7511.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10052</td>\n",
       "      <td>business</td>\n",
       "      <td>625230.6738678613</td>\n",
       "      <td>5805560.647667522</td>\n",
       "      <td>13:40:10</td>\n",
       "      <td>14:45:29</td>\n",
       "      <td>0 days 01:05:19</td>\n",
       "      <td>POINT (117655.393 488611.676)</td>\n",
       "      <td>7516.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>10052</td>\n",
       "      <td>home</td>\n",
       "      <td>625308.5056096063</td>\n",
       "      <td>5792622.8888017945</td>\n",
       "      <td>15:01:57</td>\n",
       "      <td>1 days 08:14:07</td>\n",
       "      <td>0 days 17:12:10</td>\n",
       "      <td>POINT (117306.649 475676.791)</td>\n",
       "      <td>7831.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>100572</td>\n",
       "      <td>sozializing</td>\n",
       "      <td>631054.2796505742</td>\n",
       "      <td>5817149.295519518</td>\n",
       "      <td>09:29:50</td>\n",
       "      <td>10:43:00</td>\n",
       "      <td>0 days 01:13:10</td>\n",
       "      <td>POINT (123859.082 500003.103)</td>\n",
       "      <td>5329.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>100572</td>\n",
       "      <td>home</td>\n",
       "      <td>629997.9602208312</td>\n",
       "      <td>5803597.994578412</td>\n",
       "      <td>11:03:41</td>\n",
       "      <td>1 days 09:09:00</td>\n",
       "      <td>0 days 22:05:19</td>\n",
       "      <td>POINT (122355.893 486492.597)</td>\n",
       "      <td>7510.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>100615</td>\n",
       "      <td>work</td>\n",
       "      <td>632315.3322837545</td>\n",
       "      <td>5817000.086435355</td>\n",
       "      <td>06:25:50</td>\n",
       "      <td>17:02:35</td>\n",
       "      <td>0 days 10:36:45</td>\n",
       "      <td>POINT (125114.651 499812.301)</td>\n",
       "      <td>5329.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>100615</td>\n",
       "      <td>home</td>\n",
       "      <td>631001.2759862994</td>\n",
       "      <td>5804041.676976789</td>\n",
       "      <td>17:26:56</td>\n",
       "      <td>1 days 06:02:01</td>\n",
       "      <td>0 days 12:35:05</td>\n",
       "      <td>POINT (123373.405 486902.989)</td>\n",
       "      <td>7510.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>100681</td>\n",
       "      <td>shoppingND</td>\n",
       "      <td>629192.1871217856</td>\n",
       "      <td>5804635.732271321</td>\n",
       "      <td>13:20:37</td>\n",
       "      <td>13:57:36</td>\n",
       "      <td>0 days 00:36:59</td>\n",
       "      <td>POINT (121584.703 487556.463)</td>\n",
       "      <td>7510.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>100681</td>\n",
       "      <td>home</td>\n",
       "      <td>630775.0080001679</td>\n",
       "      <td>5804463.00254444</td>\n",
       "      <td>14:00:24</td>\n",
       "      <td>17:42:11</td>\n",
       "      <td>0 days 03:41:47</td>\n",
       "      <td>POINT (123161.135 487331.593)</td>\n",
       "      <td>7510.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>100681</td>\n",
       "      <td>leisure</td>\n",
       "      <td>623442.6951386724</td>\n",
       "      <td>5793243.906416614</td>\n",
       "      <td>18:05:07</td>\n",
       "      <td>21:38:01</td>\n",
       "      <td>0 days 03:32:54</td>\n",
       "      <td>POINT (115462.079 476359.022)</td>\n",
       "      <td>7831.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>100681</td>\n",
       "      <td>home</td>\n",
       "      <td>630775.0080001679</td>\n",
       "      <td>5804463.00254444</td>\n",
       "      <td>21:59:52</td>\n",
       "      <td>1 days 13:15:27</td>\n",
       "      <td>0 days 15:15:35</td>\n",
       "      <td>POINT (123161.135 487331.593)</td>\n",
       "      <td>7510.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>100806</td>\n",
       "      <td>work</td>\n",
       "      <td>638653.6948047496</td>\n",
       "      <td>5796600.87829093</td>\n",
       "      <td>07:03:03</td>\n",
       "      <td>13:14:24</td>\n",
       "      <td>0 days 06:11:21</td>\n",
       "      <td>POINT (130776.988 479213.242)</td>\n",
       "      <td>5013.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>100806</td>\n",
       "      <td>home</td>\n",
       "      <td>630485.7323446143</td>\n",
       "      <td>5803136.725430627</td>\n",
       "      <td>13:27:48</td>\n",
       "      <td>1 days 06:48:57</td>\n",
       "      <td>0 days 17:21:09</td>\n",
       "      <td>POINT (122828.237 486015.441)</td>\n",
       "      <td>7514.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>10097</td>\n",
       "      <td>work</td>\n",
       "      <td>619078.8222061335</td>\n",
       "      <td>5793266.895838001</td>\n",
       "      <td>08:29:28</td>\n",
       "      <td>17:27:49</td>\n",
       "      <td>0 days 08:58:21</td>\n",
       "      <td>POINT (111100.739 476525.783)</td>\n",
       "      <td>5601.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>10097</td>\n",
       "      <td>home</td>\n",
       "      <td>634456.1049276257</td>\n",
       "      <td>5793373.482339734</td>\n",
       "      <td>17:52:12</td>\n",
       "      <td>18:10:18</td>\n",
       "      <td>0 days 00:18:06</td>\n",
       "      <td>POINT (126474.977 476125.666)</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>10097</td>\n",
       "      <td>service</td>\n",
       "      <td>627734.7744314364</td>\n",
       "      <td>5801190.426952196</td>\n",
       "      <td>18:38:06</td>\n",
       "      <td>19:47:57</td>\n",
       "      <td>0 days 01:09:51</td>\n",
       "      <td>POINT (120014.283 484160.714)</td>\n",
       "      <td>7513.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>10097</td>\n",
       "      <td>home</td>\n",
       "      <td>634456.1049276257</td>\n",
       "      <td>5793373.482339734</td>\n",
       "      <td>20:03:04</td>\n",
       "      <td>1 days 08:10:01</td>\n",
       "      <td>0 days 12:06:57</td>\n",
       "      <td>POINT (126474.977 476125.666)</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>10099</td>\n",
       "      <td>work</td>\n",
       "      <td>630009.7635401655</td>\n",
       "      <td>5803830.816817541</td>\n",
       "      <td>09:27:22</td>\n",
       "      <td>18:25:41</td>\n",
       "      <td>0 days 08:58:19</td>\n",
       "      <td>POINT (122375.371 486724.928)</td>\n",
       "      <td>7510.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>10099</td>\n",
       "      <td>home</td>\n",
       "      <td>634456.1049276257</td>\n",
       "      <td>5793373.482339734</td>\n",
       "      <td>18:48:58</td>\n",
       "      <td>1 days 09:11:33</td>\n",
       "      <td>0 days 14:22:35</td>\n",
       "      <td>POINT (126474.977 476125.666)</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>10100</td>\n",
       "      <td>work</td>\n",
       "      <td>629435.8293064734</td>\n",
       "      <td>5803842.271639743</td>\n",
       "      <td>07:45:51</td>\n",
       "      <td>17:47:19</td>\n",
       "      <td>0 days 10:01:28</td>\n",
       "      <td>POINT (121802.065 486755.310)</td>\n",
       "      <td>7510.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>10100</td>\n",
       "      <td>home</td>\n",
       "      <td>634456.1049276257</td>\n",
       "      <td>5793373.482339734</td>\n",
       "      <td>18:15:47</td>\n",
       "      <td>1 days 07:30:30</td>\n",
       "      <td>0 days 13:14:43</td>\n",
       "      <td>POINT (126474.977 476125.666)</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>101154</td>\n",
       "      <td>sozializing</td>\n",
       "      <td>617212.8247856302</td>\n",
       "      <td>5793659.172381698</td>\n",
       "      <td>09:18:12</td>\n",
       "      <td>12:07:35</td>\n",
       "      <td>0 days 02:49:23</td>\n",
       "      <td>POINT (109248.405 476979.386)</td>\n",
       "      <td>5601.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>101154</td>\n",
       "      <td>home</td>\n",
       "      <td>630543.4389452781</td>\n",
       "      <td>5803946.491865685</td>\n",
       "      <td>12:25:38</td>\n",
       "      <td>18:09:15</td>\n",
       "      <td>0 days 05:43:37</td>\n",
       "      <td>POINT (122912.629 486822.948)</td>\n",
       "      <td>7510.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>101154</td>\n",
       "      <td>sozializing</td>\n",
       "      <td>627117.9798324348</td>\n",
       "      <td>5794942.823215407</td>\n",
       "      <td>18:28:46</td>\n",
       "      <td>21:40:51</td>\n",
       "      <td>0 days 03:12:05</td>\n",
       "      <td>POINT (119191.798 477936.119)</td>\n",
       "      <td>7831.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>101154</td>\n",
       "      <td>home</td>\n",
       "      <td>630543.4389452781</td>\n",
       "      <td>5803946.491865685</td>\n",
       "      <td>21:56:20</td>\n",
       "      <td>1 days 09:00:18</td>\n",
       "      <td>0 days 11:03:58</td>\n",
       "      <td>POINT (122912.629 486822.948)</td>\n",
       "      <td>7510.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>101365</td>\n",
       "      <td>work</td>\n",
       "      <td>617212.8247856302</td>\n",
       "      <td>5793659.172381698</td>\n",
       "      <td>07:24:27</td>\n",
       "      <td>17:09:08</td>\n",
       "      <td>0 days 09:44:41</td>\n",
       "      <td>POINT (109248.405 476979.386)</td>\n",
       "      <td>5601.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>101365</td>\n",
       "      <td>home</td>\n",
       "      <td>631352.1275582332</td>\n",
       "      <td>5803944.718054838</td>\n",
       "      <td>17:39:42</td>\n",
       "      <td>1 days 07:05:14</td>\n",
       "      <td>0 days 13:25:32</td>\n",
       "      <td>POINT (123720.903 486794.499)</td>\n",
       "      <td>7510.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>10150</td>\n",
       "      <td>work</td>\n",
       "      <td>625203.0960825895</td>\n",
       "      <td>5804892.799500055</td>\n",
       "      <td>06:37:03</td>\n",
       "      <td>15:59:32</td>\n",
       "      <td>0 days 09:22:29</td>\n",
       "      <td>POINT (117605.794 487945.018)</td>\n",
       "      <td>7516.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>10150</td>\n",
       "      <td>home</td>\n",
       "      <td>634456.1049276257</td>\n",
       "      <td>5793373.482339734</td>\n",
       "      <td>16:16:28</td>\n",
       "      <td>1 days 06:19:45</td>\n",
       "      <td>0 days 14:03:17</td>\n",
       "      <td>POINT (126474.977 476125.666)</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>101512</td>\n",
       "      <td>touring</td>\n",
       "      <td>638653.6948047496</td>\n",
       "      <td>5796600.87829093</td>\n",
       "      <td>13:24:20</td>\n",
       "      <td>13:56:12</td>\n",
       "      <td>0 days 00:31:52</td>\n",
       "      <td>POINT (130776.988 479213.242)</td>\n",
       "      <td>5013.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>101512</td>\n",
       "      <td>home</td>\n",
       "      <td>630322.5076563973</td>\n",
       "      <td>5803121.051544154</td>\n",
       "      <td>14:10:55</td>\n",
       "      <td>15:18:46</td>\n",
       "      <td>0 days 01:07:51</td>\n",
       "      <td>POINT (122664.567 486005.157)</td>\n",
       "      <td>7514.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   VEHICLE activityType                  x                   y     start  \\\n",
       "0    10001         work  626348.5794967742   5803352.505475129  07:13:11   \n",
       "1    10001         home  625308.5056096063  5792622.8888017945  17:00:03   \n",
       "2   100089  sozializing  618591.4587132754   5793162.677454361  20:38:36   \n",
       "3   100089         home  630028.7167090132   5802955.596728954  22:27:16   \n",
       "4   100294  sozializing  638653.6948047496    5796600.87829093  17:39:24   \n",
       "5   100294         home  630543.4389452781   5803946.491865685  21:53:42   \n",
       "6    10052         work  612307.6747723853   5798999.945285048  08:33:46   \n",
       "7    10052     business  623442.6951386724   5793243.906416614  12:00:45   \n",
       "8    10052     business  627451.4732033794   5800136.966645968  12:37:54   \n",
       "9    10052   shoppingND  623803.4218678667   5806163.850149635  13:11:05   \n",
       "10   10052     business  625230.6738678613   5805560.647667522  13:40:10   \n",
       "11   10052         home  625308.5056096063  5792622.8888017945  15:01:57   \n",
       "12  100572  sozializing  631054.2796505742   5817149.295519518  09:29:50   \n",
       "13  100572         home  629997.9602208312   5803597.994578412  11:03:41   \n",
       "14  100615         work  632315.3322837545   5817000.086435355  06:25:50   \n",
       "15  100615         home  631001.2759862994   5804041.676976789  17:26:56   \n",
       "16  100681   shoppingND  629192.1871217856   5804635.732271321  13:20:37   \n",
       "17  100681         home  630775.0080001679    5804463.00254444  14:00:24   \n",
       "18  100681      leisure  623442.6951386724   5793243.906416614  18:05:07   \n",
       "19  100681         home  630775.0080001679    5804463.00254444  21:59:52   \n",
       "20  100806         work  638653.6948047496    5796600.87829093  07:03:03   \n",
       "21  100806         home  630485.7323446143   5803136.725430627  13:27:48   \n",
       "22   10097         work  619078.8222061335   5793266.895838001  08:29:28   \n",
       "23   10097         home  634456.1049276257   5793373.482339734  17:52:12   \n",
       "24   10097      service  627734.7744314364   5801190.426952196  18:38:06   \n",
       "25   10097         home  634456.1049276257   5793373.482339734  20:03:04   \n",
       "26   10099         work  630009.7635401655   5803830.816817541  09:27:22   \n",
       "27   10099         home  634456.1049276257   5793373.482339734  18:48:58   \n",
       "28   10100         work  629435.8293064734   5803842.271639743  07:45:51   \n",
       "29   10100         home  634456.1049276257   5793373.482339734  18:15:47   \n",
       "30  101154  sozializing  617212.8247856302   5793659.172381698  09:18:12   \n",
       "31  101154         home  630543.4389452781   5803946.491865685  12:25:38   \n",
       "32  101154  sozializing  627117.9798324348   5794942.823215407  18:28:46   \n",
       "33  101154         home  630543.4389452781   5803946.491865685  21:56:20   \n",
       "34  101365         work  617212.8247856302   5793659.172381698  07:24:27   \n",
       "35  101365         home  631352.1275582332   5803944.718054838  17:39:42   \n",
       "36   10150         work  625203.0960825895   5804892.799500055  06:37:03   \n",
       "37   10150         home  634456.1049276257   5793373.482339734  16:16:28   \n",
       "38  101512      touring  638653.6948047496    5796600.87829093  13:24:20   \n",
       "39  101512         home  630322.5076563973   5803121.051544154  14:10:55   \n",
       "\n",
       "                end        duration                       geometry  mzr_id  \n",
       "0          16:43:03 0 days 09:29:52  POINT (118699.985 486367.588)  7512.0  \n",
       "1   1 days 06:57:56 0 days 13:57:53  POINT (117306.649 475676.791)  7831.0  \n",
       "2          22:06:11 0 days 01:27:35  POINT (110610.135 476437.663)  5601.0  \n",
       "3   1 days 20:20:51 0 days 21:53:35  POINT (122365.447 485849.465)  7514.0  \n",
       "4          21:39:14 0 days 03:59:50  POINT (130776.988 479213.242)  5013.0  \n",
       "5   1 days 17:23:16 0 days 19:29:34  POINT (122912.629 486822.948)  7510.0  \n",
       "6          11:39:57 0 days 03:06:11  POINT (104521.162 482479.773)  5597.0  \n",
       "7          12:25:12 0 days 00:24:27  POINT (115462.079 476359.022)  7831.0  \n",
       "8          12:59:37 0 days 00:21:43  POINT (119696.366 483117.047)  7513.0  \n",
       "9          13:37:23 0 days 00:26:18  POINT (116248.638 489261.716)  7511.0  \n",
       "10         14:45:29 0 days 01:05:19  POINT (117655.393 488611.676)  7516.0  \n",
       "11  1 days 08:14:07 0 days 17:12:10  POINT (117306.649 475676.791)  7831.0  \n",
       "12         10:43:00 0 days 01:13:10  POINT (123859.082 500003.103)  5329.0  \n",
       "13  1 days 09:09:00 0 days 22:05:19  POINT (122355.893 486492.597)  7510.0  \n",
       "14         17:02:35 0 days 10:36:45  POINT (125114.651 499812.301)  5329.0  \n",
       "15  1 days 06:02:01 0 days 12:35:05  POINT (123373.405 486902.989)  7510.0  \n",
       "16         13:57:36 0 days 00:36:59  POINT (121584.703 487556.463)  7510.0  \n",
       "17         17:42:11 0 days 03:41:47  POINT (123161.135 487331.593)  7510.0  \n",
       "18         21:38:01 0 days 03:32:54  POINT (115462.079 476359.022)  7831.0  \n",
       "19  1 days 13:15:27 0 days 15:15:35  POINT (123161.135 487331.593)  7510.0  \n",
       "20         13:14:24 0 days 06:11:21  POINT (130776.988 479213.242)  5013.0  \n",
       "21  1 days 06:48:57 0 days 17:21:09  POINT (122828.237 486015.441)  7514.0  \n",
       "22         17:27:49 0 days 08:58:21  POINT (111100.739 476525.783)  5601.0  \n",
       "23         18:10:18 0 days 00:18:06  POINT (126474.977 476125.666)     0.0  \n",
       "24         19:47:57 0 days 01:09:51  POINT (120014.283 484160.714)  7513.0  \n",
       "25  1 days 08:10:01 0 days 12:06:57  POINT (126474.977 476125.666)     0.0  \n",
       "26         18:25:41 0 days 08:58:19  POINT (122375.371 486724.928)  7510.0  \n",
       "27  1 days 09:11:33 0 days 14:22:35  POINT (126474.977 476125.666)     0.0  \n",
       "28         17:47:19 0 days 10:01:28  POINT (121802.065 486755.310)  7510.0  \n",
       "29  1 days 07:30:30 0 days 13:14:43  POINT (126474.977 476125.666)     0.0  \n",
       "30         12:07:35 0 days 02:49:23  POINT (109248.405 476979.386)  5601.0  \n",
       "31         18:09:15 0 days 05:43:37  POINT (122912.629 486822.948)  7510.0  \n",
       "32         21:40:51 0 days 03:12:05  POINT (119191.798 477936.119)  7831.0  \n",
       "33  1 days 09:00:18 0 days 11:03:58  POINT (122912.629 486822.948)  7510.0  \n",
       "34         17:09:08 0 days 09:44:41  POINT (109248.405 476979.386)  5601.0  \n",
       "35  1 days 07:05:14 0 days 13:25:32  POINT (123720.903 486794.499)  7510.0  \n",
       "36         15:59:32 0 days 09:22:29  POINT (117605.794 487945.018)  7516.0  \n",
       "37  1 days 06:19:45 0 days 14:03:17  POINT (126474.977 476125.666)     0.0  \n",
       "38         13:56:12 0 days 00:31:52  POINT (130776.988 479213.242)  5013.0  \n",
       "39         15:18:46 0 days 01:07:51  POINT (122664.567 486005.157)  7514.0  "
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainingSet_activities = trainingSet_activities.set_crs(epsg=28992)\n",
    "labledSet = gpd.sjoin(trainingSet_activities, map_mzr.map,how = \"left\")\n",
    "labledSet.mzr_id = (np.nan_to_num((labledSet.mzr_id)))\n",
    "labledSet.drop(['index_right'],axis=1,inplace=True)\n",
    "labledSet.head(40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "45f9603d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\zahraeftekhar\\.conda\\envs\\ODmatrices\\lib\\site-packages\\pyproj\\crs\\crs.py:53: FutureWarning: '+init=<authority>:<code>' syntax is deprecated. '<authority>:<code>' is the preferred initialization method. When making the change, be mindful of axis order changes: https://pyproj4.github.io/pyproj/stable/gotchas.html#axis-order-changes-in-proj-6\n",
      "  return _prepare_from_string(\" \".join(pjargs))\n",
      "C:\\Users\\zahraeftekhar\\.conda\\envs\\ODmatrices\\lib\\site-packages\\pyproj\\crs\\crs.py:294: FutureWarning: '+init=<authority>:<code>' syntax is deprecated. '<authority>:<code>' is the preferred initialization method. When making the change, be mindful of axis order changes: https://pyproj4.github.io/pyproj/stable/gotchas.html#axis-order-changes-in-proj-6\n",
      "  projstring = _prepare_from_string(\" \".join((projstring, projkwargs)))\n",
      "C:\\Users\\zahraeftekhar\\.conda\\envs\\ODmatrices\\lib\\site-packages\\pyproj\\crs\\crs.py:53: FutureWarning: '+init=<authority>:<code>' syntax is deprecated. '<authority>:<code>' is the preferred initialization method. When making the change, be mindful of axis order changes: https://pyproj4.github.io/pyproj/stable/gotchas.html#axis-order-changes-in-proj-6\n",
      "  return _prepare_from_string(\" \".join(pjargs))\n",
      "C:\\Users\\zahraeftekhar\\.conda\\envs\\ODmatrices\\lib\\site-packages\\pyproj\\crs\\crs.py:294: FutureWarning: '+init=<authority>:<code>' syntax is deprecated. '<authority>:<code>' is the preferred initialization method. When making the change, be mindful of axis order changes: https://pyproj4.github.io/pyproj/stable/gotchas.html#axis-order-changes-in-proj-6\n",
      "  projstring = _prepare_from_string(\" \".join((projstring, projkwargs)))\n",
      "C:\\Users\\ZAHRAE~1\\AppData\\Local\\Temp/ipykernel_14136/4093888528.py:40: DeprecationWarning: This function is deprecated. See: https://pyproj4.github.io/pyproj/stable/gotchas.html#upgrading-to-pyproj-2-from-pyproj-1\n",
      "  for pt in itransform(p1,p2,points, always_xy=True):\n"
     ]
    }
   ],
   "source": [
    "# building the zero OD Matrix based on the number of zones in the SHP\n",
    "map_mzr = TAZmap()\n",
    "map_mzr.set_map(\"{a}amsterdamMezuroZones.shp\".format(a=savingLoc))\n",
    "inputs = map_mzr.map.geometry\n",
    "map_mzr.map\n",
    "#we time the process\n",
    "startTime = time.time()\n",
    "ids = pd.unique(activities.VEHICLE)\n",
    "random.seed(101)\n",
    "prop=0.10\n",
    "indices = random.sample(range(len(ids)),round(prop*len(ids))) #1% sampling of users\n",
    "indices = pd.DataFrame(indices, columns=[\"VEHICLE\"])\n",
    "trainIDs =pd.DataFrame(ids[indices])\n",
    "trainIDs.columns = [\"VEHICLE\"]\n",
    "trainingSet_trips = (trainIDs.merge(trips, on=[\"VEHICLE\"], how=\"inner\", sort=True,validate=\"1:m\"))\n",
    "trainingSet_activities = (trainIDs.merge(activities, on=[\"VEHICLE\"], how=\"inner\", sort=True,validate=\"1:m\"))\n",
    "\n",
    "# with open('{a}/trainingActivity_seed{s}.pickle'.format(a=savingLoc,s=seed), 'wb') as handle:\n",
    "#     pickle.dump(trainingSet_activities, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "# with open('{a}trainingTrip_seed{s}.pickle'.format(a=savingLoc,s=seed), 'wb') as handle:\n",
    "#     pickle.dump(trainingSet_trips, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "# inputs[0].contains(Point(52,40))\n",
    "# from pyproj import Proj, transform\n",
    "# from shapely.geometry import Point\n",
    "# for i in np.arange(0,100):\n",
    "#         inputs[i].contains(Point(transform(Proj(init='epsg:23031'), Proj(init='epsg:28992'), trainingSet_activities.x[0], trainingSet_activities.y[0])))\n",
    "points = list(zip([float(num) for num in (trainingSet_activities.x.values)],[float(num) for num in (trainingSet_activities.y.values)]))\n",
    "from pyproj import Proj, itransform\n",
    "# projection 1: WGS84\n",
    "# (defined by epsg code 4326)\n",
    "p1 = Proj(init='epsg:23031')\n",
    "# projection 2: GGRS87 / Greek Grid\n",
    "p2 = Proj(init='epsg:28992')\n",
    "# Three points with coordinates lon, lat in p1\n",
    "# points = [(22.95, 40.63), (22.81, 40.53), (23.51, 40.86)]\n",
    "# transform this point to projection 2 coordinates.\n",
    "ptsX = []\n",
    "ptsY = []\n",
    "for pt in itransform(p1,p2,points, always_xy=True): \n",
    "    from shapely.geometry import Point\n",
    "    ptsX = ptsX + [pt[0]]\n",
    "    ptsY = ptsY + [pt[1]]\n",
    "\n",
    "# trainingSet_activities[\"long\"] = gpd.GeoSeries.from_wkt(pts)\n",
    "trainingSet_activities = gpd.GeoDataFrame(trainingSet_activities, geometry=gpd.points_from_xy(ptsX,ptsY))\n",
    "trainingSet_activities = trainingSet_activities.set_crs(epsg=28992)\n",
    "labledSet = gpd.sjoin(trainingSet_activities, map_mzr.map,how = \"left\")\n",
    "labledSet.mzr_id = (np.nan_to_num((labledSet.mzr_id)))\n",
    "labledSet.drop(['index_right'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "e38e6d21",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\zahraeftekhar\\.conda\\envs\\ODmatrices\\lib\\site-packages\\pyproj\\crs\\crs.py:53: FutureWarning: '+init=<authority>:<code>' syntax is deprecated. '<authority>:<code>' is the preferred initialization method. When making the change, be mindful of axis order changes: https://pyproj4.github.io/pyproj/stable/gotchas.html#axis-order-changes-in-proj-6\n",
      "  return _prepare_from_string(\" \".join(pjargs))\n",
      "C:\\Users\\zahraeftekhar\\.conda\\envs\\ODmatrices\\lib\\site-packages\\pyproj\\crs\\crs.py:294: FutureWarning: '+init=<authority>:<code>' syntax is deprecated. '<authority>:<code>' is the preferred initialization method. When making the change, be mindful of axis order changes: https://pyproj4.github.io/pyproj/stable/gotchas.html#axis-order-changes-in-proj-6\n",
      "  projstring = _prepare_from_string(\" \".join((projstring, projkwargs)))\n",
      "C:\\Users\\zahraeftekhar\\.conda\\envs\\ODmatrices\\lib\\site-packages\\pyproj\\crs\\crs.py:53: FutureWarning: '+init=<authority>:<code>' syntax is deprecated. '<authority>:<code>' is the preferred initialization method. When making the change, be mindful of axis order changes: https://pyproj4.github.io/pyproj/stable/gotchas.html#axis-order-changes-in-proj-6\n",
      "  return _prepare_from_string(\" \".join(pjargs))\n",
      "C:\\Users\\zahraeftekhar\\.conda\\envs\\ODmatrices\\lib\\site-packages\\pyproj\\crs\\crs.py:294: FutureWarning: '+init=<authority>:<code>' syntax is deprecated. '<authority>:<code>' is the preferred initialization method. When making the change, be mindful of axis order changes: https://pyproj4.github.io/pyproj/stable/gotchas.html#axis-order-changes-in-proj-6\n",
      "  projstring = _prepare_from_string(\" \".join((projstring, projkwargs)))\n",
      "C:\\Users\\ZAHRAE~1\\AppData\\Local\\Temp/ipykernel_14136/3224500027.py:61: DeprecationWarning: This function is deprecated. See: https://pyproj4.github.io/pyproj/stable/gotchas.html#upgrading-to-pyproj-2-from-pyproj-1\n",
      "  for pt in itransform(p1,p2,points, always_xy=True):\n"
     ]
    }
   ],
   "source": [
    "#we time the process\n",
    "startTime = time.time()\n",
    "ids = pd.unique(activities.VEHICLE)\n",
    "random.seed(101)\n",
    "prop=0.10\n",
    "indices = random.sample(range(len(ids)),round(prop*len(ids))) #1% sampling of users\n",
    "indices = pd.DataFrame(indices, columns=[\"VEHICLE\"])\n",
    "trainIDs =pd.DataFrame(ids[indices])\n",
    "trainIDs.columns = [\"VEHICLE\"]\n",
    "# trainingSet_trips = (trainIDs.merge(trips, on=[\"VEHICLE\"], how=\"inner\", sort=True,validate=\"1:m\"))\n",
    "trainingSet_activities = (trainIDs.merge(activities, on=[\"VEHICLE\"], how=\"inner\", sort=True,validate=\"1:m\"))\n",
    "\n",
    "# with open('{a}/trainingActivity_seed{s}.pickle'.format(a=savingLoc,s=seed), 'wb') as handle:\n",
    "#     pickle.dump(trainingSet_activities, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "# with open('{a}trainingTrip_seed{s}.pickle'.format(a=savingLoc,s=seed), 'wb') as handle:\n",
    "#     pickle.dump(trainingSet_trips, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# building the zero OD Matrix based on the number of zones in the SHP\n",
    "map_mzr = TAZmap()\n",
    "map_mzr.set_map(\"{a}amsterdamMezuroZones.shp\".format(a=savingLoc))\n",
    "inputs = map_mzr.map.geometry\n",
    "map_mzr.map\n",
    "#we time the process\n",
    "startTime = time.time()\n",
    "ids = pd.unique(activities.VEHICLE)\n",
    "random.seed(101)\n",
    "prop=0.10\n",
    "indices = random.sample(range(len(ids)),round(prop*len(ids))) #1% sampling of users\n",
    "indices = pd.DataFrame(indices, columns=[\"VEHICLE\"])\n",
    "trainIDs =pd.DataFrame(ids[indices])\n",
    "trainIDs.columns = [\"VEHICLE\"]\n",
    "trainingSet_trips = (trainIDs.merge(trips, on=[\"VEHICLE\"], how=\"inner\", sort=True,validate=\"1:m\"))\n",
    "trainingSet_activities = (trainIDs.merge(activities, on=[\"VEHICLE\"], how=\"inner\", sort=True,validate=\"1:m\"))\n",
    "\n",
    "# with open('{a}/trainingActivity_seed{s}.pickle'.format(a=savingLoc,s=seed), 'wb') as handle:\n",
    "#     pickle.dump(trainingSet_activities, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "# with open('{a}trainingTrip_seed{s}.pickle'.format(a=savingLoc,s=seed), 'wb') as handle:\n",
    "#     pickle.dump(trainingSet_trips, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "# inputs[0].contains(Point(52,40))\n",
    "# from pyproj import Proj, transform\n",
    "# from shapely.geometry import Point\n",
    "# for i in np.arange(0,100):\n",
    "#         inputs[i].contains(Point(transform(Proj(init='epsg:23031'), Proj(init='epsg:28992'), trainingSet_activities.x[0], trainingSet_activities.y[0])))\n",
    "points = list(zip([float(num) for num in (trainingSet_activities.x.values)],[float(num) for num in (trainingSet_activities.y.values)]))\n",
    "from pyproj import Proj, itransform\n",
    "# projection 1: WGS84\n",
    "# (defined by epsg code 4326)\n",
    "p1 = Proj(init='epsg:23031')\n",
    "# projection 2: GGRS87 / Greek Grid\n",
    "p2 = Proj(init='epsg:28992')\n",
    "# Three points with coordinates lon, lat in p1\n",
    "# points = [(22.95, 40.63), (22.81, 40.53), (23.51, 40.86)]\n",
    "# transform this point to projection 2 coordinates.\n",
    "ptsX = []\n",
    "ptsY = []\n",
    "for pt in itransform(p1,p2,points, always_xy=True): \n",
    "    from shapely.geometry import Point\n",
    "    ptsX = ptsX + [pt[0]]\n",
    "    ptsY = ptsY + [pt[1]]\n",
    "\n",
    "# trainingSet_activities[\"long\"] = gpd.GeoSeries.from_wkt(pts)\n",
    "trainingSet_activities = gpd.GeoDataFrame(trainingSet_activities, geometry=gpd.points_from_xy(ptsX,ptsY))\n",
    "trainingSet_activities = trainingSet_activities.set_crs(epsg=28992)\n",
    "trainingSet_activities = gpd.sjoin(trainingSet_activities, map_mzr.map,how = \"left\")\n",
    "trainingSet_activities.mzr_id = (np.nan_to_num((trainingSet_activities.mzr_id)))\n",
    "trainingSet_activities.drop(['index_right'],axis=1,inplace=True)\n",
    "\n",
    "\n",
    "trainingSet_home = trainingSet_activities[trainingSet_activities.activityType == \"home\"]\n",
    "trainingSet_work = trainingSet_activities[trainingSet_activities.activityType == \"work\"]\n",
    "trainingSet_other = trainingSet_activities[(trainingSet_activities.activityType != \"home\") & (trainingSet_activities.activityType != \"work\")]\n",
    "trainingSet_home.to_csv(\"{a}trainingHome_prop{s}.CSV\".format(a=savingLoc,s=prop),index=False,header=True)\n",
    "trainingSet_work.to_csv(\"{a}trainingWork_prop{s}.CSV\".format(a=savingLoc,s=prop),index=False,header=True)\n",
    "trainingSet_other.to_csv(\"{a}trainingOther_prop{s}.CSV\".format(a=savingLoc,s=prop),index=False,header=True)\n",
    "\n",
    "# with open('{a}trainingHome_seed{s}.pickle'.format(a=savingLoc,s=seed), 'wb') as handle:\n",
    "#     pickle.dump(trainingSet_home, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "# with open('{a}trainingWork_seed{s}.pickle'.format(a=savingLoc,s=seed), 'wb') as handle:\n",
    "#     pickle.dump(trainingSet_work, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "# with open('{a}trainingOther_seed{s}.pickle'.format(a=savingLoc,s=seed), 'wb') as handle:\n",
    "#     pickle.dump(trainingSet_other, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "5d09ff7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>VEHICLE</th>\n",
       "      <th>activityType</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>duration</th>\n",
       "      <th>geometry</th>\n",
       "      <th>mzr_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10001</td>\n",
       "      <td>home</td>\n",
       "      <td>625308.5056096063</td>\n",
       "      <td>5792622.8888017945</td>\n",
       "      <td>17:00:03</td>\n",
       "      <td>1 days 06:57:56</td>\n",
       "      <td>0 days 13:57:53</td>\n",
       "      <td>POINT (117306.649 475676.791)</td>\n",
       "      <td>7831.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100089</td>\n",
       "      <td>home</td>\n",
       "      <td>630028.7167090132</td>\n",
       "      <td>5802955.596728954</td>\n",
       "      <td>22:27:16</td>\n",
       "      <td>1 days 20:20:51</td>\n",
       "      <td>0 days 21:53:35</td>\n",
       "      <td>POINT (122365.447 485849.465)</td>\n",
       "      <td>7514.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>100294</td>\n",
       "      <td>home</td>\n",
       "      <td>630543.4389452781</td>\n",
       "      <td>5803946.491865685</td>\n",
       "      <td>21:53:42</td>\n",
       "      <td>1 days 17:23:16</td>\n",
       "      <td>0 days 19:29:34</td>\n",
       "      <td>POINT (122912.629 486822.948)</td>\n",
       "      <td>7510.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>10052</td>\n",
       "      <td>home</td>\n",
       "      <td>625308.5056096063</td>\n",
       "      <td>5792622.8888017945</td>\n",
       "      <td>15:01:57</td>\n",
       "      <td>1 days 08:14:07</td>\n",
       "      <td>0 days 17:12:10</td>\n",
       "      <td>POINT (117306.649 475676.791)</td>\n",
       "      <td>7831.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>100572</td>\n",
       "      <td>home</td>\n",
       "      <td>629997.9602208312</td>\n",
       "      <td>5803597.994578412</td>\n",
       "      <td>11:03:41</td>\n",
       "      <td>1 days 09:09:00</td>\n",
       "      <td>0 days 22:05:19</td>\n",
       "      <td>POINT (122355.893 486492.597)</td>\n",
       "      <td>7510.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5817</th>\n",
       "      <td>99721</td>\n",
       "      <td>home</td>\n",
       "      <td>628959.7643920127</td>\n",
       "      <td>5803554.357180867</td>\n",
       "      <td>16:11:41</td>\n",
       "      <td>1 days 06:29:18</td>\n",
       "      <td>0 days 14:17:37</td>\n",
       "      <td>POINT (121316.710 486483.224)</td>\n",
       "      <td>7510.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5819</th>\n",
       "      <td>9974</td>\n",
       "      <td>home</td>\n",
       "      <td>625308.5056096063</td>\n",
       "      <td>5792622.8888017945</td>\n",
       "      <td>17:10:09</td>\n",
       "      <td>1 days 07:11:11</td>\n",
       "      <td>0 days 14:01:02</td>\n",
       "      <td>POINT (117306.649 475676.791)</td>\n",
       "      <td>7831.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5822</th>\n",
       "      <td>99799</td>\n",
       "      <td>home</td>\n",
       "      <td>628774.5976465159</td>\n",
       "      <td>5802753.050154505</td>\n",
       "      <td>21:29:21</td>\n",
       "      <td>1 days 14:59:22</td>\n",
       "      <td>0 days 17:30:01</td>\n",
       "      <td>POINT (121105.193 485688.371)</td>\n",
       "      <td>7513.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5824</th>\n",
       "      <td>99876</td>\n",
       "      <td>home</td>\n",
       "      <td>628959.7643920127</td>\n",
       "      <td>5803554.357180867</td>\n",
       "      <td>17:46:42</td>\n",
       "      <td>19:34:52</td>\n",
       "      <td>0 days 01:48:10</td>\n",
       "      <td>POINT (121316.710 486483.224)</td>\n",
       "      <td>7510.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5826</th>\n",
       "      <td>99876</td>\n",
       "      <td>home</td>\n",
       "      <td>628959.7643920127</td>\n",
       "      <td>5803554.357180867</td>\n",
       "      <td>20:11:47</td>\n",
       "      <td>1 days 06:17:54</td>\n",
       "      <td>0 days 10:06:07</td>\n",
       "      <td>POINT (121316.710 486483.224)</td>\n",
       "      <td>7510.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2718 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     VEHICLE activityType                  x                   y     start  \\\n",
       "1      10001         home  625308.5056096063  5792622.8888017945  17:00:03   \n",
       "3     100089         home  630028.7167090132   5802955.596728954  22:27:16   \n",
       "5     100294         home  630543.4389452781   5803946.491865685  21:53:42   \n",
       "11     10052         home  625308.5056096063  5792622.8888017945  15:01:57   \n",
       "13    100572         home  629997.9602208312   5803597.994578412  11:03:41   \n",
       "...      ...          ...                ...                 ...       ...   \n",
       "5817   99721         home  628959.7643920127   5803554.357180867  16:11:41   \n",
       "5819    9974         home  625308.5056096063  5792622.8888017945  17:10:09   \n",
       "5822   99799         home  628774.5976465159   5802753.050154505  21:29:21   \n",
       "5824   99876         home  628959.7643920127   5803554.357180867  17:46:42   \n",
       "5826   99876         home  628959.7643920127   5803554.357180867  20:11:47   \n",
       "\n",
       "                  end        duration                       geometry  mzr_id  \n",
       "1     1 days 06:57:56 0 days 13:57:53  POINT (117306.649 475676.791)  7831.0  \n",
       "3     1 days 20:20:51 0 days 21:53:35  POINT (122365.447 485849.465)  7514.0  \n",
       "5     1 days 17:23:16 0 days 19:29:34  POINT (122912.629 486822.948)  7510.0  \n",
       "11    1 days 08:14:07 0 days 17:12:10  POINT (117306.649 475676.791)  7831.0  \n",
       "13    1 days 09:09:00 0 days 22:05:19  POINT (122355.893 486492.597)  7510.0  \n",
       "...               ...             ...                            ...     ...  \n",
       "5817  1 days 06:29:18 0 days 14:17:37  POINT (121316.710 486483.224)  7510.0  \n",
       "5819  1 days 07:11:11 0 days 14:01:02  POINT (117306.649 475676.791)  7831.0  \n",
       "5822  1 days 14:59:22 0 days 17:30:01  POINT (121105.193 485688.371)  7513.0  \n",
       "5824         19:34:52 0 days 01:48:10  POINT (121316.710 486483.224)  7510.0  \n",
       "5826  1 days 06:17:54 0 days 10:06:07  POINT (121316.710 486483.224)  7510.0  \n",
       "\n",
       "[2718 rows x 9 columns]"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainingSet_home"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
