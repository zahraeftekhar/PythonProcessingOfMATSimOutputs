{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f3aedcb2",
   "metadata": {},
   "source": [
    "# Estimation and Analysis of the ground-truth OD matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df9c88e4",
   "metadata": {},
   "source": [
    "#### adding required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "60dc51d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import time\n",
    "import sys\n",
    "# !conda install --yes --prefix {sys.prefix} pyproj\n",
    "# !{sys.executable} -m pip install geopandas\n",
    "from pyproj import Proj, transform\n",
    "from shapely.geometry import Point\n",
    "import geopandas as gpd\n",
    "import random\n",
    "from scipy.stats import gaussian_kde\n",
    "import datetime as dt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "192eea68",
   "metadata": {},
   "source": [
    "#### specifying the saving location "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c46e1cf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "savingLoc = \"Y:/ZahraEftekhar/phase4/\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "810b8506",
   "metadata": {},
   "source": [
    "#### functions for proximity analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7612e1cb",
   "metadata": {},
   "source": [
    "Here, we create classes and functions to automate the proximity analysis. These analyses include changing the coordinate system, mapping the location coordinates to their associated TAZ (traffic analysis zone)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7c25437a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#this class change coordinate system and map location coordinates to zones:\n",
    "class LongLat:\n",
    "    def __init__(self, *args):\n",
    "        self.TAZ = 0\n",
    "    def set_location(self, x, y):\n",
    "        from shapely.geometry import Point\n",
    "        self.location = Point(x, y)\n",
    "\n",
    "    def changeCoordSys(self, initial: str = 'epsg:23031', final: str = 'epsg:28992'):\n",
    "        from pyproj import Proj, transform\n",
    "        from shapely.geometry import Point\n",
    "        self.location = Point(transform(Proj(init=initial), Proj(init=final), self.location.x, self.location.y))\n",
    "\n",
    "    def zoneMapping(self, onepolygon, polygonName):\n",
    "        if (onepolygon.contains(self.location)):\n",
    "            self.TAZ = polygonName\n",
    "# this class only reads SHP:\n",
    "class TAZmap:\n",
    "    def __init__(self): pass\n",
    "\n",
    "    def set_map(self, value):\n",
    "        import geopandas as gpd\n",
    "        self.map = gpd.read_file(value)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "079bdb2b",
   "metadata": {},
   "source": [
    "#### building the zero OD Matrix based on the number of zones in the SHP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dafad35e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# building the zero OD Matrix based on the number of zones in the SHP\n",
    "map_mzr = TAZmap()\n",
    "map_mzr.set_map(\"{a}amsterdamMezuroZones.shp\".format(a=savingLoc))\n",
    "inputs = map_mzr.map.geometry\n",
    "amsterdamMezuroZones = pd.read_csv(\"{a}amsterdamMezuroZones.CSV\".format(a=savingLoc), usecols=['mzr_id'])\n",
    "tazNames = amsterdamMezuroZones['mzr_id']\n",
    "zoneZero = pd.Series(0)\n",
    "matrixRowColNames = tuple(zoneZero.append(tazNames))\n",
    "odsize=len(matrixRowColNames)\n",
    "del map_mzr\n",
    "ODMatrix_df = pd.DataFrame(np.zeros((odsize, odsize), dtype=np.int32), columns=matrixRowColNames,\n",
    "                           index=matrixRowColNames)  # creating empty OD matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9bd9bc9",
   "metadata": {},
   "source": [
    "## Specifying the OD matrix estimation interval\n",
    "========================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "4f61f168",
   "metadata": {},
   "outputs": [],
   "source": [
    "ODstart = \"06:30:00\"\n",
    "ODend = \"09:30:00\"\n",
    "startTime_OD = pd.to_timedelta(ODstart)\n",
    "endTime_OD = pd.to_timedelta(ODend)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51da44ba",
   "metadata": {},
   "source": [
    "#### Reading the travel diaries to estimate the OD matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "60e03f49",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('{a}1.trueLocExperienced.pickle'.format(a=savingLoc), 'rb') as handle:\n",
    "    itemlistExperienced = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5edbb8c4",
   "metadata": {},
   "source": [
    "======================================================================================================"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67d26d0d",
   "metadata": {},
   "source": [
    "#### estimating the ground-truth OD matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we time the process\n",
    "startTime = time.time()\n",
    "for ID in itemlistExperienced.keys():#itemlistExperienced.keys() or ['100158'] or ['100048']\n",
    "    activityListExperienced = itemlistExperienced[ID]\n",
    "    activityListExperienced.loc[:,\"end\"].iloc[-1] = pd.to_timedelta(activityListExperienced.loc[:,\"end\"].iloc[-1]\n",
    "                                                                  )+ pd.to_timedelta('24:00:00')\n",
    "    j=1\n",
    "    while j < len(np.arange(len(activityListExperienced))):\n",
    "        if j==len(np.arange(len(activityListExperienced)))-1:\n",
    "            start_time1 = pd.to_timedelta((activityListExperienced.loc[:,\"start\"]).iloc[j])\n",
    "            end_time1 = pd.to_timedelta((activityListExperienced.loc[:,\"end\"]).iloc[j])\n",
    "            start_time2 = pd.to_timedelta((activityListExperienced.loc[:,\"start\"]).iloc[0])+ pd.to_timedelta('24:00:00')\n",
    "            endActivity = end_time1\n",
    "            startNewActivity = start_time2\n",
    "            if pd.to_timedelta('23:59:59')>=pd.to_timedelta(ODstart)>=pd.to_timedelta(start_time1):\n",
    "                startTime_OD = pd.to_timedelta(ODstart)\n",
    "            else:\n",
    "                startTime_OD = pd.to_timedelta(ODstart) + pd.to_timedelta('24:00:00')\n",
    "            if pd.to_timedelta('23:59:59')>= pd.to_timedelta(ODend) >=pd.to_timedelta(start_time1):\n",
    "                endTime_OD =pd.to_timedelta(ODend)\n",
    "            else:\n",
    "                endTime_OD = pd.to_timedelta(ODend)+ pd.to_timedelta('24:00:00')\n",
    "        else:\n",
    "            start_time1 = pd.to_timedelta(activityListExperienced.loc[:,\"start\"].iloc[j])\n",
    "            end_time1 = pd.to_timedelta(activityListExperienced.loc[:,\"end\"].iloc[j])\n",
    "            start_time2 = pd.to_timedelta(activityListExperienced.loc[:,\"start\"].iloc[j+1])\n",
    "            endActivity = end_time1 \n",
    "            startNewActivity = start_time2 \n",
    "        if pd.to_timedelta(start_time1) <= pd.to_timedelta(startTime_OD) < pd.to_timedelta(startNewActivity):\n",
    "            if endTime_OD <= endActivity:\n",
    "                break\n",
    "            else:\n",
    "                while pd.to_timedelta(endTime_OD) > pd.to_timedelta(endActivity):\n",
    "                    point1 = LongLat()\n",
    "                    point1.set_location(x=float(activityListExperienced.loc[:,\"x\"].iloc[j]),\n",
    "                                        y=float(activityListExperienced.loc[:,\"y\"].iloc[j]))#*********ghablan:j-1\n",
    "                    point1.changeCoordSys()\n",
    "                    for k in range(len(tazNames)):\n",
    "                        point1.zoneMapping(inputs[k], tazNames[k])\n",
    "                    origin = point1.TAZ\n",
    "                    point2 = LongLat()\n",
    "                    if j == len(activityListExperienced) - 1:\n",
    "                        point2.set_location(x=float(activityListExperienced.loc[:,\"x\"].iloc[0]),\n",
    "                                            y=float(activityListExperienced.loc[:,\"y\"].iloc[0]))\n",
    "                    else:\n",
    "                        point2.set_location(x=float(activityListExperienced.loc[:,\"x\"].iloc[j+1]),\n",
    "                                        y=float(activityListExperienced.loc[:,\"y\"].iloc[j+1])) #*****ghablan: j\n",
    "                    point2.changeCoordSys()\n",
    "                    for k in range(len(tazNames)):\n",
    "                        point2.zoneMapping(inputs[k], tazNames[k])\n",
    "                    destination = point2.TAZ\n",
    "                    ODMatrix_df[origin][destination] = ODMatrix_df[origin][destination] + 1\n",
    "                    j += 1\n",
    "                    if j > len(np.arange(len(activityListExperienced))) - 1: break\n",
    "                    if j== len(np.arange(len(activityListExperienced)))-1:\n",
    "                        end_time1 = pd.to_timedelta((activityListExperienced.loc[:,\"end\"]).iloc[0])+ pd.to_timedelta('24:00:00')\n",
    "                    else:\n",
    "                        end_time1 = pd.to_timedelta((activityListExperienced.loc[:,\"end\"]).iloc[j])\n",
    "                    endActivity = end_time1\n",
    "                break\n",
    "        j += 1\n",
    "TXTFileName = \"{a}OD({start1}-{start2}_{end1}-{end2}).pickle\".format(a=savingLoc,start1 = ODstart[0:2],\n",
    "                                                                                     start2 = ODstart[3:5],\n",
    "                                                                     end1 = ODend[0:2], end2 = ODend[3:5])\n",
    "with open(TXTFileName, 'wb') as handle:\n",
    "    pickle.dump(ODMatrix_df, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "print((time.time() - startTime)//60,'minutes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "c36c2b1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11948\n"
     ]
    }
   ],
   "source": [
    "print(np.sum(np.sum(ODMatrix_df, axis=0)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "================================================================================\n",
    "### creating a `dict` file of all the trips that each user has in its travel diaries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>VEHICLE</th>\n",
       "      <th>activityType</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>work</td>\n",
       "      <td>629393.6676188618</td>\n",
       "      <td>5803949.115843206</td>\n",
       "      <td>06:52:04</td>\n",
       "      <td>16:49:20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>home</td>\n",
       "      <td>632315.3322837545</td>\n",
       "      <td>5817000.086435355</td>\n",
       "      <td>17:10:47</td>\n",
       "      <td>06:29:59</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  VEHICLE activityType                  x                  y     start  \\\n",
       "0       1         work  629393.6676188618  5803949.115843206  06:52:04   \n",
       "0       1         home  632315.3322837545  5817000.086435355  17:10:47   \n",
       "\n",
       "        end  \n",
       "0  16:49:20  \n",
       "0  06:29:59  "
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "itemlistExperienced[\"1\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\programdata\\anaconda3\\envs\\extractingodfromxml\\lib\\site-packages\\pandas\\core\\indexing.py:670: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_with_indexer(indexer, value)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0 minutes\n"
     ]
    }
   ],
   "source": [
    "#we time the process\n",
    "startTime = time.time()\n",
    "\n",
    "trips = {}\n",
    "for ID in itemlistExperienced.keys():\n",
    "    activities= itemlistExperienced[ID]\n",
    "    activities.columns = [\"VEHICLE\",\"activityType\",\"x\",\"y\",\"A_start\",\"A_end\"]\n",
    "    activities[\"start\"] = 0\n",
    "    activities[\"duration\"] = 0\n",
    "    \n",
    "    for j in np.arange(0,len(activities)):\n",
    "            activities.loc[:,\"start\"].iloc[j] = pd.to_timedelta(activities.loc[:,\"A_end\"].iloc[j-1])\n",
    "            activities.loc[:,\"duration\"].iloc[j]=pd.to_timedelta(activities.loc[:,\"A_start\"].iloc[j])-pd.to_timedelta(activities.loc[:,\"A_end\"].iloc[j-1])\n",
    "    activities.drop([\"activityType\",\"x\",\"y\",\"A_start\",\"A_end\"],axis=1,inplace=True)\n",
    "    trips[ID] = activities\n",
    "TXTFileName = \"{a}trips.pickle\".format(a=savingLoc)\n",
    "with open(TXTFileName, 'wb') as handle:\n",
    "    pickle.dump(trips, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "print((time.time() - startTime)//60,'minutes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>VEHICLE</th>\n",
       "      <th>start</th>\n",
       "      <th>duration</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0 days 06:29:59</td>\n",
       "      <td>0 days 00:22:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0 days 16:49:20</td>\n",
       "      <td>0 days 00:21:27</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  VEHICLE            start         duration\n",
       "0       1  0 days 06:29:59  0 days 00:22:05\n",
       "0       1  0 days 16:49:20  0 days 00:21:27"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trips[\"1\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### analysis of the ground truth location and activity type identification:\n",
    "Here, we use Bayesian Theory to compute the probability of each even and activity, then infer the category depending on the temporal characteristics of each record (i.e starting time and duration). Remmember, we have to include Mezuro zone id instead of location coordinates to represent the spatial aggregation due to the fact that in empirical data the BTS location is reported, NOT the user's location. This only means that the diagonal of the OD matrix becomes zero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('{a}1.trueLocExperienced.pickle'.format(a=savingLoc), 'rb') as handle:\n",
    "    activities = pickle.load(handle)\n",
    "for ID in activities.keys():\n",
    "    activities[ID].loc[:,\"end\"].iloc[-1] = pd.to_timedelta(activities[ID].loc[:,\"end\"].iloc[-1]\n",
    "                                                                  )+ pd.to_timedelta('24:00:00')\n",
    "    activities[ID].loc[:,\"duration\"] =  pd.to_timedelta(activities[ID].loc[:,\"end\"])-pd.to_timedelta(activities[ID].loc[:,\"start\"])\n",
    "#this file is the same as `1.trueLocExperienced.pickle` except that it also includes the duration of activities\n",
    "TXTFileName = \"{a}activities.pickle\".format(a=savingLoc)\n",
    "with open(TXTFileName, 'wb') as handle:\n",
    "    pickle.dump(activities, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"{a}trips.pickle\".format(a=savingLoc),'rb') as handle:\n",
    "    trips = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "#generating dataframe of trips and activities for the ease of operations and visualizability\n",
    "activity_df = pd.DataFrame()\n",
    "trip_df = pd.DataFrame()\n",
    "for ID in activities.keys():\n",
    "    activity_df = activity_df.append(activities[ID])\n",
    "    trip_df = trip_df.append(trips[ID])\n",
    "activity_df.reset_index(drop=True,inplace=True)\n",
    "trip_df.reset_index(drop=True,inplace=True)\n",
    "with open('{a}activity_df.pickle'.format(a=savingLoc), 'wb') as handle:\n",
    "    pickle.dump(activity_df, handle, protocol=pickle.HIGHEST_PROTOCOL)    \n",
    "with open('{a}trip_df.pickle'.format(a=savingLoc), 'wb') as handle:\n",
    "    pickle.dump(trip_df, handle, protocol=pickle.HIGHEST_PROTOCOL)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>VEHICLE</th>\n",
       "      <th>activityType</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>duration</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>work</td>\n",
       "      <td>629393.6676188618</td>\n",
       "      <td>5803949.115843206</td>\n",
       "      <td>06:52:04</td>\n",
       "      <td>16:49:20</td>\n",
       "      <td>09:57:16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>home</td>\n",
       "      <td>632315.3322837545</td>\n",
       "      <td>5817000.086435355</td>\n",
       "      <td>17:10:47</td>\n",
       "      <td>1 days 06:29:59</td>\n",
       "      <td>13:19:12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10</td>\n",
       "      <td>work</td>\n",
       "      <td>627192.4415982522</td>\n",
       "      <td>5799465.4065392725</td>\n",
       "      <td>06:01:34</td>\n",
       "      <td>15:27:02</td>\n",
       "      <td>09:25:28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10</td>\n",
       "      <td>home</td>\n",
       "      <td>632315.3322837545</td>\n",
       "      <td>5817000.086435355</td>\n",
       "      <td>15:54:40</td>\n",
       "      <td>1 days 05:35:01</td>\n",
       "      <td>13:40:21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100007</td>\n",
       "      <td>work</td>\n",
       "      <td>634456.1049276257</td>\n",
       "      <td>5793373.482339734</td>\n",
       "      <td>06:32:44</td>\n",
       "      <td>15:59:53</td>\n",
       "      <td>09:27:09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  VEHICLE activityType                  x                   y     start  \\\n",
       "0       1         work  629393.6676188618   5803949.115843206  06:52:04   \n",
       "1       1         home  632315.3322837545   5817000.086435355  17:10:47   \n",
       "2      10         work  627192.4415982522  5799465.4065392725  06:01:34   \n",
       "3      10         home  632315.3322837545   5817000.086435355  15:54:40   \n",
       "4  100007         work  634456.1049276257   5793373.482339734  06:32:44   \n",
       "\n",
       "               end duration  \n",
       "0         16:49:20 09:57:16  \n",
       "1  1 days 06:29:59 13:19:12  \n",
       "2         15:27:02 09:25:28  \n",
       "3  1 days 05:35:01 13:40:21  \n",
       "4         15:59:53 09:27:09  "
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "activity_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we generate __training sets__ from trips and activities. This includes the trips and activity of 1% of the users. each training record is the label, duration and starting time of that event/activity. Then we use the entire data as the test set to identify the location/activity category. The location category is either `stay`(activity) or `pass-by`(trip). The activity categories are either `home`, `work` or `other`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('{a}activity_df.pickle'.format(a=savingLoc), 'rb') as handle:\n",
    "    activities = pickle.load(handle)\n",
    "with open(\"{a}trip_df.pickle\".format(a=savingLoc), 'rb') as handle:\n",
    "    trips = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>VEHICLE</th>\n",
       "      <th>activityType</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>duration</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>work</td>\n",
       "      <td>629393.6676188618</td>\n",
       "      <td>5803949.115843206</td>\n",
       "      <td>06:52:04</td>\n",
       "      <td>16:49:20</td>\n",
       "      <td>09:57:16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10</td>\n",
       "      <td>work</td>\n",
       "      <td>627192.4415982522</td>\n",
       "      <td>5799465.4065392725</td>\n",
       "      <td>06:01:34</td>\n",
       "      <td>15:27:02</td>\n",
       "      <td>09:25:28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100007</td>\n",
       "      <td>work</td>\n",
       "      <td>634456.1049276257</td>\n",
       "      <td>5793373.482339734</td>\n",
       "      <td>06:32:44</td>\n",
       "      <td>15:59:53</td>\n",
       "      <td>09:27:09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>100009</td>\n",
       "      <td>work</td>\n",
       "      <td>638653.6948047496</td>\n",
       "      <td>5796600.87829093</td>\n",
       "      <td>07:30:27</td>\n",
       "      <td>16:28:27</td>\n",
       "      <td>08:58:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>10001</td>\n",
       "      <td>work</td>\n",
       "      <td>626348.5794967742</td>\n",
       "      <td>5803352.505475129</td>\n",
       "      <td>07:13:11</td>\n",
       "      <td>16:43:03</td>\n",
       "      <td>09:29:52</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  VEHICLE activityType                  x                   y     start  \\\n",
       "0       1         work  629393.6676188618   5803949.115843206  06:52:04   \n",
       "2      10         work  627192.4415982522  5799465.4065392725  06:01:34   \n",
       "4  100007         work  634456.1049276257   5793373.482339734  06:32:44   \n",
       "6  100009         work  638653.6948047496    5796600.87829093  07:30:27   \n",
       "8   10001         work  626348.5794967742   5803352.505475129  07:13:11   \n",
       "\n",
       "        end duration  \n",
       "0  16:49:20 09:57:16  \n",
       "2  15:27:02 09:25:28  \n",
       "4  15:59:53 09:27:09  \n",
       "6  16:28:27 08:58:00  \n",
       "8  16:43:03 09:29:52  "
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "work.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[False False False ... False False False]\n",
      "[False False False ... False False False]\n"
     ]
    }
   ],
   "source": [
    "s=0\n",
    "seed = 101\n",
    "ids = pd.unique(activities.VEHICLE)\n",
    "random.seed(seed)\n",
    "indices = random.sample(range(len(ids)),round(.01*len(ids))) #1% sampling of users\n",
    "indices = pd.DataFrame(indices, columns=[\"VEHICLE\"])\n",
    "trainIDs =pd.DataFrame(ids[indices])\n",
    "trainIDs.columns = [\"VEHICLE\"]\n",
    "trainingSet_trips = (trainIDs.merge(trips, on=[\"VEHICLE\"], how=\"inner\", sort=True,validate=\"1:m\"))\n",
    "trainingSet_activities = (trainIDs.merge(activities, on=[\"VEHICLE\"], how=\"inner\", sort=True,validate=\"1:m\"))\n",
    "trainingSet_home = trainingSet_activities[trainingSet_activities.activityType == \"home\"]\n",
    "trainingSet_work = trainingSet_activities[trainingSet_activities.activityType == \"work\"]\n",
    "trainingSet_other = trainingSet_activities[(trainingSet_activities.activityType != \"home\") & (trainingSet_activities.activityType != \"work\")]\n",
    "home = activities[activities.activityType== \"home\"]\n",
    "work = activities[activities.activityType== \"work\"]\n",
    "other = activities[(activities.activityType != \"home\") & (activities.activityType != \"work\")]\n",
    "prior_activity = len(activities)/(len(activities) + len(trips))\n",
    "prior_trip =  len(trips)/(len(activities) + len(trips))\n",
    "prior_home = len(trainingSet_home)/(len(trainingSet_home) + len(trainingSet_work) + len(trainingSet_other))\n",
    "prior_work =  len(trainingSet_work)/(len(trainingSet_home) + len(trainingSet_work) + len(trainingSet_other))\n",
    "prior_other = len(trainingSet_other)/(len(trainingSet_home) + len(trainingSet_work) + len(trainingSet_other))\n",
    "\n",
    "\n",
    "\n",
    "# sum(np.log(prior_trip+((gaussian_kde((\n",
    "#         pd.to_timedelta(trainingSet_trips.start)).dt.total_seconds()).pdf((\n",
    "#         pd.to_timedelta(activities.start)).dt.total_seconds())))+((gaussian_kde(\n",
    "#         (pd.to_timedelta(trainingSet_trips.duration)).dt.total_seconds()).pdf((\n",
    "#         pd.to_timedelta(activities.duration)).dt.total_seconds()))))<=np.log(prior_activity+((gaussian_kde((\n",
    "#         pd.to_timedelta(trainingSet_activities.start)).dt.total_seconds()).pdf((\n",
    "#         pd.to_timedelta(activities.start)).dt.total_seconds())))+((gaussian_kde(\n",
    "#         (pd.to_timedelta(trainingSet_activities.duration)).dt.total_seconds()).pdf((\n",
    "#         pd.to_timedelta(activities.duration)).dt.total_seconds())))))/len(activities)\n",
    "\n",
    "#wrong formula\n",
    "print(np.log(prior_work+((gaussian_kde((\n",
    "        pd.to_timedelta(trainingSet_work.start)).dt.total_seconds()).pdf((\n",
    "        pd.to_timedelta(work.start)).dt.total_seconds())))+((gaussian_kde(\n",
    "        (pd.to_timedelta(trainingSet_work.duration)).dt.total_seconds()).pdf((\n",
    "        pd.to_timedelta(work.duration)).dt.total_seconds()))))>=np.log(prior_home+((gaussian_kde((\n",
    "        pd.to_timedelta(trainingSet_home.start)).dt.total_seconds()).pdf((\n",
    "        pd.to_timedelta(work.start)).dt.total_seconds())))+((gaussian_kde(\n",
    "        (pd.to_timedelta(trainingSet_home.duration)).dt.total_seconds()).pdf((\n",
    "        pd.to_timedelta(work.duration)).dt.total_seconds()))))) \n",
    "print(np.log(prior_work+((gaussian_kde((\n",
    "        pd.to_timedelta(trainingSet_work.start)).dt.total_seconds()).pdf((\n",
    "        pd.to_timedelta(work.start)).dt.total_seconds())))+((gaussian_kde(\n",
    "        (pd.to_timedelta(trainingSet_work.duration)).dt.total_seconds()).pdf((\n",
    "        pd.to_timedelta(work.duration)).dt.total_seconds()))))>=np.log(prior_other+((gaussian_kde((\n",
    "        pd.to_timedelta(trainingSet_other.start)).dt.total_seconds()).pdf((\n",
    "        pd.to_timedelta(work.start)).dt.total_seconds())))+((gaussian_kde(\n",
    "        (pd.to_timedelta(trainingSet_other.duration)).dt.total_seconds()).pdf((\n",
    "        pd.to_timedelta(work.duration)).dt.total_seconds())))))\n",
    "# np.log(prior_home)+np.log(\n",
    "#         gaussian_kde(trainingSet_home['duration'].dt.total_seconds())\n",
    "#             .pdf(home['duration'].dt.total_seconds()))+np.log(\n",
    "#         gaussian_kde(trainingSet_home['start'].dt.total_seconds())\n",
    "#             .pdf(home['start'].dt.total_seconds()))+np.log((home[\"home\"]).astype(float))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9211386381724891"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "54396/len(activities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'start_time' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-204-f976e290ccc9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0msensitivityTable\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mseedSet\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mseed\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mseedSet\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mend\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'______ time:{tt}sec\\n'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtt\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mstart_time\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m     \u001b[0mids\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mactivities\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mVEHICLE\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mseed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mseed\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'start_time' is not defined"
     ]
    }
   ],
   "source": [
    "#we time the process\n",
    "startTime = time.time()\n",
    "\n",
    "# _______________test seed based on user sampling _________________________________\n",
    "seedSet = np.arange(101,151)\n",
    "sensitivityTable = pd.DataFrame(index=seedSet)\n",
    "sensitivityTable.index=seedSet\n",
    "for s, seed in enumerate(seedSet):\n",
    "    print(s, end='______ time:{tt}sec\\n'.format(tt=time.time() - start_time))\n",
    "    ids = pd.unique(activities.VEHICLE)\n",
    "    random.seed(seed)\n",
    "    indices = random.sample(range(len(ids)),round(.01*len(ids))) #1% sampling of users\n",
    "    indices = pd.DataFrame(indices, columns=[\"VEHICLE\"])\n",
    "    trainIDs =pd.DataFrame(ids[indices])\n",
    "    trainIDs.columns = [\"VEHICLE\"]\n",
    "    trainingSet_trips = (trainIDs.merge(trips, on=[\"VEHICLE\"], how=\"inner\", sort=True,validate=\"1:m\"))\n",
    "    trainingSet_activities = (trainIDs.merge(activities, on=[\"VEHICLE\"], how=\"inner\", sort=True,validate=\"1:m\"))\n",
    "    with open('{a}/trainingActivity_seed{s}.pickle'.format(a=savingLoc,s=seed), 'wb') as handle:\n",
    "        pickle.dump(trainingSet_activities, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    with open('{a}trainingTrip_seed{s}.pickle'.format(a=savingLoc,s=seed), 'wb') as handle:\n",
    "        pickle.dump(trainingSet_trips, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "\n",
    "    trainingSet_home = trainingSet_activities[trainingSet_activities.activityType == \"home\"]\n",
    "    trainingSet_work = trainingSet_activities[trainingSet_activities.activityType == \"work\"]\n",
    "    trainingSet_other = trainingSet_activities[(trainingSet_activities.activityType != \"home\") & (trainingSet_activities.activityType != \"work\")]\n",
    "\n",
    "    # ________________________________________________________________________________________\n",
    "    # ****************************************************************************************\n",
    "    home = activities[activities.activityType== \"home\"]\n",
    "    work = activities[activities.activityType== \"work\"]\n",
    "    other = activities[(activities.activityType != \"home\") & (activities.activityType != \"work\")]\n",
    "    # ****************************************************************************************\n",
    "    # ________________________ writing data: Trainset _________________________\n",
    "\n",
    "    # ________________________________________________________________\n",
    "\n",
    "    # ___________________________ Probability calculations_________________________________________\n",
    "    #***************************************************************************\n",
    "    prior_activity = len(activities)/(len(activities) + len(trips))\n",
    "    prior_trip =  len(trips)/(len(activities) + len(trips))\n",
    "#     activities['Log prob activity'] = np.log(prior_activity+((gaussian_kde((\n",
    "#         pd.to_timedelta(trainingSet_activities.start)).dt.total_seconds()).pdf((\n",
    "#         pd.to_timedelta(activities.start)).dt.total_seconds())))+((gaussian_kde(\n",
    "#         (pd.to_timedelta(trainingSet_activities.duration)).dt.total_seconds()).pdf((\n",
    "#         pd.to_timedelta(activities.duration)).dt.total_seconds()))))\n",
    "\n",
    "#     activities['Log prob trip'] = np.log(prior_trip+((gaussian_kde((\n",
    "#         pd.to_timedelta(trainingSet_trips.start)).dt.total_seconds()).pdf((\n",
    "#         pd.to_timedelta(activities.start)).dt.total_seconds())))+((gaussian_kde(\n",
    "#         (pd.to_timedelta(trainingSet_trips.duration)).dt.total_seconds()).pdf((\n",
    "#         pd.to_timedelta(activities.duration)).dt.total_seconds()))))\n",
    "    activities['activity?'] = np.log(prior_trip+((gaussian_kde((\n",
    "        pd.to_timedelta(trainingSet_trips.start)).dt.total_seconds()).pdf((\n",
    "        pd.to_timedelta(activities.start)).dt.total_seconds())))+((gaussian_kde(\n",
    "        (pd.to_timedelta(trainingSet_trips.duration)).dt.total_seconds()).pdf((\n",
    "        pd.to_timedelta(activities.duration)).dt.total_seconds()))))<=np.log(prior_activity+((gaussian_kde((\n",
    "        pd.to_timedelta(trainingSet_activities.start)).dt.total_seconds()).pdf((\n",
    "        pd.to_timedelta(activities.start)).dt.total_seconds())))+((gaussian_kde(\n",
    "        (pd.to_timedelta(trainingSet_activities.duration)).dt.total_seconds()).pdf((\n",
    "        pd.to_timedelta(activities.duration)).dt.total_seconds()))))\n",
    "    sensitivityTable.loc[seed,\"stay accuracy\"] = sum(activities['activity?'])/len(activities)\n",
    "    # print(sum(activities['activity?'])/len(activities['activity?']))\n",
    "    #***************************************************************************\n",
    "#     trips['Log prob activity'] = np.log(prior_activity)+np.log(\n",
    "#         gaussian_kde(trainingSet_activities['duration'].dt.total_seconds())\n",
    "#             .pdf(trips['duration'].dt.total_seconds()))+np.log(\n",
    "#         gaussian_kde(trainingSet_activities['start'].dt.total_seconds())\n",
    "#             .pdf(trips['start'].dt.total_seconds()))\n",
    "\n",
    "#     trips['Log prob trip'] = np.log(prior_trip)+np.log(\n",
    "#         gaussian_kde(trainingSet_trips['duration'].dt.total_seconds())\n",
    "#             .pdf(trips['duration'].dt.total_seconds()))+np.log(\n",
    "#         gaussian_kde(trainingSet_trips['start'].dt.total_seconds())\n",
    "#             .pdf(trips['start'].dt.total_seconds()))\n",
    "    trips['trip?'] = np.log(prior_trip+((gaussian_kde((\n",
    "        pd.to_timedelta(trainingSet_trips.start)).dt.total_seconds()).pdf((\n",
    "        pd.to_timedelta(trips.start)).dt.total_seconds())))+((gaussian_kde(\n",
    "        (pd.to_timedelta(trainingSet_trips.duration)).dt.total_seconds()).pdf((\n",
    "        pd.to_timedelta(trips.duration)).dt.total_seconds()))))>=np.log(prior_activity+((gaussian_kde((\n",
    "        pd.to_timedelta(trainingSet_activities.start)).dt.total_seconds()).pdf((\n",
    "        pd.to_timedelta(trips.start)).dt.total_seconds())))+((gaussian_kde(\n",
    "        (pd.to_timedelta(trainingSet_activities.duration)).dt.total_seconds()).pdf((\n",
    "        pd.to_timedelta(trips.duration)).dt.total_seconds()))))\n",
    "    sensitivityTable.loc[seed,\"pass-by accuracy\"] = sum(trips['trip?'])/len(trips)\n",
    "\n",
    "    # print(sum(trips['trip?'])/len(trips['trip?']))\n",
    "    #***************************************************************************\n",
    "\n",
    "    prior_home = len(trainingSet_home)/(len(trainingSet_home) + len(trainingSet_work) + len(trainingSet_other))\n",
    "    prior_work =  len(trainingSet_work)/(len(trainingSet_home) + len(trainingSet_work) + len(trainingSet_other))\n",
    "    prior_other = len(trainingSet_other)/(len(trainingSet_home) + len(trainingSet_work) + len(trainingSet_other))\n",
    "\n",
    "#     home['Log prob home'] = np.log(prior_home)+np.log(\n",
    "#         gaussian_kde(trainingSet_home['duration'].dt.total_seconds())\n",
    "#             .pdf(home['duration'].dt.total_seconds()))+np.log(\n",
    "#         gaussian_kde(trainingSet_home['start'].dt.total_seconds())\n",
    "#             .pdf(home['start'].dt.total_seconds()))+np.log((home[\"home\"]).astype(float)) #todo: problem of log(0) for loc\n",
    "\n",
    "#     home['Log prob work'] = np.log(prior_work) + np.log(\n",
    "#         gaussian_kde(trainingSet_work['duration'].dt.total_seconds())\n",
    "#             .pdf(home['duration'].dt.total_seconds())) + np.log(\n",
    "#         gaussian_kde(trainingSet_work['start'].dt.total_seconds())\n",
    "#             .pdf(home['start'].dt.total_seconds())) + np.log(\n",
    "#         (home[\"work\"]).astype(float))  # todo: problem of log(0) for loc\n",
    "\n",
    "#     home['Log prob other'] = np.log(prior_other) + np.log(\n",
    "#         gaussian_kde(trainingSet_other['duration'].dt.total_seconds())\n",
    "#             .pdf(home['duration'].dt.total_seconds())) + np.log(\n",
    "#         gaussian_kde(trainingSet_other['start'].dt.total_seconds())\n",
    "#             .pdf(home['start'].dt.total_seconds())) + np.log(\n",
    "#         (home[\"other\"]).astype(float))  # todo: problem of log(0) for loc\n",
    "\n",
    "    home['activity?'] = (np.log(prior_home+((gaussian_kde((\n",
    "        pd.to_timedelta(trainingSet_home.start)).dt.total_seconds()).pdf((\n",
    "        pd.to_timedelta(home.start)).dt.total_seconds())))+((gaussian_kde(\n",
    "        (pd.to_timedelta(trainingSet_trips.duration)).dt.total_seconds()).pdf((\n",
    "        pd.to_timedelta(home.duration)).dt.total_seconds()))))>=np.log(prior_work+((gaussian_kde((\n",
    "        pd.to_timedelta(trainingSet_work.start)).dt.total_seconds()).pdf((\n",
    "        pd.to_timedelta(home.start)).dt.total_seconds())))+((gaussian_kde(\n",
    "        (pd.to_timedelta(trainingSet_work.duration)).dt.total_seconds()).pdf((\n",
    "        pd.to_timedelta(home.duration)).dt.total_seconds()))))) &(np.log(prior_home+((gaussian_kde((\n",
    "        pd.to_timedelta(trainingSet_home.start)).dt.total_seconds()).pdf((\n",
    "        pd.to_timedelta(home.start)).dt.total_seconds())))+((gaussian_kde(\n",
    "        (pd.to_timedelta(trainingSet_home.duration)).dt.total_seconds()).pdf((\n",
    "        pd.to_timedelta(home.duration)).dt.total_seconds()))))>=np.log(prior_other+((gaussian_kde((\n",
    "        pd.to_timedelta(trainingSet_other.start)).dt.total_seconds()).pdf((\n",
    "        pd.to_timedelta(home.start)).dt.total_seconds())))+((gaussian_kde(\n",
    "        (pd.to_timedelta(trainingSet_other.duration)).dt.total_seconds()).pdf((\n",
    "        pd.to_timedelta(home.duration)).dt.total_seconds())))))\n",
    "    sensitivityTable.loc[seed,\"home accuracy\"] = len([home['activity?'])/len(home)\n",
    "\n",
    "    # print(\"home accuracy: \",len(home[home['activity?']=='Log prob home'])/len(home))\n",
    "#***************************************************************************\n",
    "#     work['Log prob home'] = np.log(prior_home)+np.log(\n",
    "#         gaussian_kde(trainingSet_home['duration'].dt.total_seconds())\n",
    "#             .pdf(work['duration'].dt.total_seconds()))+np.log(\n",
    "#         gaussian_kde(trainingSet_home['start'].dt.total_seconds())\n",
    "#             .pdf(work['start'].dt.total_seconds()))+np.log((work[\"home\"]).astype(float)) #todo: problem of log(0) for\n",
    "\n",
    "\n",
    "#     work['Log prob work'] = np.log(prior_work) + np.log(\n",
    "#         gaussian_kde(trainingSet_work['duration'].dt.total_seconds())\n",
    "#             .pdf(work['duration'].dt.total_seconds())) + np.log(\n",
    "#         gaussian_kde(trainingSet_work['start'].dt.total_seconds())\n",
    "#             .pdf(work['start'].dt.total_seconds())) + np.log(\n",
    "#         (work[\"work\"]).astype(float))  # todo: problem of log(0) for loc\n",
    "\n",
    "#     work['Log prob other'] = np.log(prior_other) + np.log(\n",
    "#         gaussian_kde(trainingSet_other['duration'].dt.total_seconds())\n",
    "#             .pdf(work['duration'].dt.total_seconds())) + np.log(\n",
    "#         gaussian_kde(trainingSet_other['start'].dt.total_seconds())\n",
    "#             .pdf(work['start'].dt.total_seconds())) + np.log(\n",
    "#         (work[\"other\"]).astype(float))  # todo: problem of log(0) for loc\n",
    "\n",
    "    work['activity?'] = work[['Log prob home','Log prob work','Log prob other']].idxmax(axis=1)\n",
    "    sensitivityTable.loc[seed, \"work accuracy\"] = len(work[work['activity?']=='Log prob work'])/len(work)\n",
    "    # print(\"work accuracy: \",len(work[work['activity?']=='Log prob work'])/len(work))\n",
    "#***************************************************************************\n",
    "    other['Log prob home'] = np.log(prior_home)+np.log(\n",
    "        gaussian_kde(trainingSet_home['duration'].dt.total_seconds())\n",
    "            .pdf(other['duration'].dt.total_seconds()))+np.log(\n",
    "        gaussian_kde(trainingSet_home['start'].dt.total_seconds())\n",
    "            .pdf(other['start'].dt.total_seconds()))+np.log((other[\"home\"]).astype(float)) #todo: problem of log(0) for\n",
    "    # loc\n",
    "\n",
    "    other['Log prob work'] = np.log(prior_work) + np.log(\n",
    "        gaussian_kde(trainingSet_work['duration'].dt.total_seconds())\n",
    "            .pdf(other['duration'].dt.total_seconds())) + np.log(\n",
    "        gaussian_kde(trainingSet_work['start'].dt.total_seconds())\n",
    "            .pdf(other['start'].dt.total_seconds())) + np.log(\n",
    "        (other[\"work\"]).astype(float))  # todo: problem of log(0) for loc\n",
    "\n",
    "    other['Log prob other'] = np.log(prior_other) + np.log(\n",
    "        gaussian_kde(trainingSet_other['duration'].dt.total_seconds())\n",
    "            .pdf(other['duration'].dt.total_seconds())) + np.log(\n",
    "        gaussian_kde(trainingSet_other['start'].dt.total_seconds())\n",
    "            .pdf(other['start'].dt.total_seconds())) + np.log(\n",
    "        (other[\"other\"]).astype(float))  # todo: problem of log(0) for loc\n",
    "\n",
    "    other['activity?'] = other[['Log prob home','Log prob work','Log prob other']].idxmax(axis=1)\n",
    "    sensitivityTable.loc[seed, \"other accuracy\"] = len(other[other['activity?']=='Log prob other'])/len(other)\n",
    "#   print(\"other accuracy: \",len(other[other['activity?']=='Log prob other'])/len(other))\n",
    "#     ***************************************************************************\n",
    "    home.to_csv(\"D:/ax/gis/phase2/trainingHome_seed{s}.CSV\".format(s=seed),index=False,header=True)\n",
    "    work.to_csv(\"D:/ax/gis/phase2/trainingWork_seed{s}.CSV\".format(s=seed),index=False,header=True)\n",
    "    other.to_csv(\"D:/ax/gis/phase2/trainingOther_seed{s}.CSV\".format(s=seed),index=False,header=True)\n",
    "\n",
    "    with open('D:/ax/gis/phase2/trainingHome_seed{s}.pickle'.format(s=seed), 'wb') as handle:\n",
    "        pickle.dump(home, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    with open('D:/ax/gis/phase2/trainingWork_seed{s}.pickle'.format(s=seed), 'wb') as handle:\n",
    "        pickle.dump(work, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    with open('D:/ax/gis/phase2/trainingOther_seed{s}.pickle'.format(s=seed), 'wb') as handle:\n",
    "        pickle.dump(other, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "sensitivityTable.to_excel(\"D:/ax/gis/phase2/userSampling_onePercentLocationDetectionSensitivity.xlsx\", header=True,\n",
    "                          index=True)\n",
    "print((time.time() - startTime)//60,'minutes')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
